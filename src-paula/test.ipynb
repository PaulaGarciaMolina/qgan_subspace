{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f12364bc",
   "metadata": {},
   "source": [
    "# Test qWGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c25d0e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import CFG\n",
    "from tools.training_init import run_single_training\n",
    "from time import perf_counter as tpc\n",
    "import copy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa96dfed",
   "metadata": {},
   "source": [
    "## 1. Single run"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1473e9",
   "metadata": {},
   "source": [
    "### 1.1. One epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d22ec4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = copy.deepcopy(CFG)\n",
    "\n",
    "config.run_multiple_experiments = False\n",
    "config.system_size = 2\n",
    "config.extra_ancilla = False\n",
    "config.epochs = 1\n",
    "config.iterations_epoch = 20\n",
    "config.gen_layers = 1\n",
    "config.gen_ansatz = \"XX_YY_ZZ_Z\"\n",
    "config.target_hamiltonian = \"custom_h\"\n",
    "config.custom_hamiltonian_terms = [\"ZZZ\", \"ZZ\", \"XX\", \"XZ\"]\n",
    "config.label_suffix = \"c1_2q_1l_noanc_XXYYZZZ_CustomH_ZZZ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "68774bdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in SINGLE RUN mode.\n",
      "\n",
      "\n",
      "================================================== \n",
      "run_timestamp: 2025-07-25__10-23-47,\n",
      "----------------------------------------------\n",
      "load_timestamp: None,\n",
      "type_of_warm_start: none,\n",
      "warm_start_strength: 0.1,\n",
      "----------------------------------------------\n",
      "system_size: 3,\n",
      "extra_ancilla: False,\n",
      "ancilla_mode: pass,\n",
      "ancilla_project_norm: re-norm,\n",
      "ancilla_topology: bridge,\n",
      "ancilla_connect_to: None,\n",
      "do_ancilla_1q_gates: False,\n",
      "start_ancilla_gates_randomly: False,\n",
      "----------------------------------------------\n",
      "gen_layers: 3,\n",
      "gen_ansatz: ZZ_X_Z,\n",
      "----------------------------------------------\n",
      "target_hamiltonian: custom_h,\n",
      "custom_hamiltonian_terms: ['XZ', 'X'],\n",
      "custom_hamiltonian_strengths: [1.0, 0.1],\n",
      "----------------------------------------------\n",
      "epochs: 10,\n",
      "iterations_epoch: 300,\n",
      "log_every_x_iter: 10,\n",
      "save_fid_and_loss_every_x_iter: 1,\n",
      "max_fidelity: 0.99,\n",
      "steps_gen: 1,\n",
      "steps_dis: 1,\n",
      "----------------------------------------------\n",
      "l_rate: 0.01,\n",
      "momentum_coeff: 0.9,\n",
      "================================================== \n",
      "\n",
      "\n",
      "Epoch:    1 | Iter:    1 | Fidelity: 0.016954 | Loss: -3.448095\n",
      "\n",
      "Epoch:    1 | Iter:   11 | Fidelity: 0.016751 | Loss: -3.339991\n",
      "\n",
      "Epoch:    1 | Iter:   21 | Fidelity: 0.016176 | Loss: -3.264212\n",
      "\n",
      "Epoch:    1 | Iter:   31 | Fidelity: 0.013879 | Loss: -3.241571\n",
      "\n",
      "Epoch:    1 | Iter:   41 | Fidelity: 0.008805 | Loss: -3.016555\n",
      "\n",
      "Epoch:    1 | Iter:   51 | Fidelity: 0.005279 | Loss: -2.637948\n",
      "\n",
      "Epoch:    1 | Iter:   61 | Fidelity: 0.003373 | Loss: -2.060892\n",
      "\n",
      "Epoch:    1 | Iter:   71 | Fidelity: 0.002364 | Loss: -0.693833\n",
      "\n",
      "Epoch:    1 | Iter:   81 | Fidelity: 0.001978 | Loss: 0.021283\n",
      "\n",
      "Epoch:    1 | Iter:   91 | Fidelity: 0.001874 | Loss: 0.211199\n",
      "\n",
      "Epoch:    1 | Iter:  101 | Fidelity: 0.001868 | Loss: 0.262415\n",
      "\n",
      "Epoch:    1 | Iter:  111 | Fidelity: 0.001900 | Loss: 0.290056\n",
      "\n",
      "Epoch:    1 | Iter:  121 | Fidelity: 0.001948 | Loss: 0.299677\n",
      "\n",
      "Epoch:    1 | Iter:  131 | Fidelity: 0.002004 | Loss: 0.303948\n",
      "\n",
      "Epoch:    1 | Iter:  141 | Fidelity: 0.002064 | Loss: 0.304625\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m t0 = tpc()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m res = \u001b[43mrun_single_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCFG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m t1 = tpc()\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mRuntime = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt1-t0\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\tools\\training_init.py:47\u001b[39m, in \u001b[36mrun_single_training\u001b[39m\u001b[34m(config, verbose, seed)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     43\u001b[39m     \u001b[38;5;66;03m##############################################################\u001b[39;00m\n\u001b[32m     44\u001b[39m     \u001b[38;5;66;03m# Run single training instance with specified configuration\u001b[39;00m\n\u001b[32m     45\u001b[39m     \u001b[38;5;66;03m##############################################################\u001b[39;00m\n\u001b[32m     46\u001b[39m     training_instance = Training(config=config, verbose=verbose, seed=seed)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     res = \u001b[43mtraining_instance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m     success_msg = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mDefault configuration run COMPLETED SUCCESSFULLY.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\qgan\\training.py:78\u001b[39m, in \u001b[36mTraining.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.config.iterations_epoch):\n\u001b[32m     74\u001b[39m     \u001b[38;5;66;03m# --- Train Discriminator ---\u001b[39;00m\n\u001b[32m     75\u001b[39m     \u001b[38;5;66;03m# We need to detach the generator's output from the computation graph\u001b[39;00m\n\u001b[32m     76\u001b[39m     \u001b[38;5;66;03m# when training the discriminator to avoid backpropagating through the generator.\u001b[39;00m\n\u001b[32m     77\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m         total_gen_state = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43minitial_state_total\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     final_gen_state_detached = get_final_gen_state_for_discriminator(total_gen_state)\n\u001b[32m     81\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.config.steps_dis):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\f52ga\\miniforge3\\envs\\qgan\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\f52ga\\miniforge3\\envs\\qgan\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\qgan\\generator.py:137\u001b[39m, in \u001b[36mGenerator.forward\u001b[39m\u001b[34m(self, total_input_state)\u001b[39m\n\u001b[32m    135\u001b[39m \u001b[38;5;66;03m# Get the unitary matrix representation of the quantum circuit\u001b[39;00m\n\u001b[32m    136\u001b[39m device = total_input_state.device\n\u001b[32m--> \u001b[39m\u001b[32m137\u001b[39m generator_unitary = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mansatz\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m.to(device)\n\u001b[32m    139\u001b[39m \u001b[38;5;66;03m# The full operator includes the identity on the untouched qubits\u001b[39;00m\n\u001b[32m    140\u001b[39m \u001b[38;5;66;03m# Identity is created on the correct device by the qgates module\u001b[39;00m\n\u001b[32m    141\u001b[39m full_op = torch.kron(Identity(\u001b[38;5;28mself\u001b[39m.target_size), generator_unitary)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\f52ga\\miniforge3\\envs\\qgan\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\f52ga\\miniforge3\\envs\\qgan\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\qgan\\generator.py:45\u001b[39m, in \u001b[36mAnsatz.forward\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     44\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m---> \u001b[39m\u001b[32m45\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mqc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\f52ga\\miniforge3\\envs\\qgan\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\f52ga\\miniforge3\\envs\\qgan\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\tools\\qobjects\\qcircuit.py:56\u001b[39m, in \u001b[36mQuantumCircuit.forward\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     53\u001b[39m \u001b[38;5;66;03m# Apply each gate in sequence\u001b[39;00m\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m gate \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.gates:\n\u001b[32m     55\u001b[39m     \u001b[38;5;66;03m# Get the matrix for the current gate\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m     g = \u001b[43mgate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     57\u001b[39m     \u001b[38;5;66;03m# Left-multiply the gate to the total circuit matrix\u001b[39;00m\n\u001b[32m     58\u001b[39m     matrix = torch.matmul(g, matrix)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\f52ga\\miniforge3\\envs\\qgan\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\f52ga\\miniforge3\\envs\\qgan\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\tools\\qobjects\\qgates.py:138\u001b[39m, in \u001b[36mQuantumGate.forward\u001b[39m\u001b[34m(self, size)\u001b[39m\n\u001b[32m    136\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Y_Rotation(size, \u001b[38;5;28mself\u001b[39m.qubit1, \u001b[38;5;28mself\u001b[39m.angle)\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.name == \u001b[33m\"\u001b[39m\u001b[33mZ\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m138\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mZ_Rotation\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mqubit1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mangle\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    139\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.name == \u001b[33m\"\u001b[39m\u001b[33mG\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    140\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m Global_phase(size, \u001b[38;5;28mself\u001b[39m.angle)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\tools\\qobjects\\qgates.py:91\u001b[39m, in \u001b[36mZ_Rotation\u001b[39m\u001b[34m(size, qubit, param)\u001b[39m\n\u001b[32m     89\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mZ_Rotation\u001b[39m(size: \u001b[38;5;28mint\u001b[39m, qubit: \u001b[38;5;28mint\u001b[39m, param: torch.Tensor) -> torch.Tensor:\n\u001b[32m     90\u001b[39m     P = _construct_operator(size, {qubit: Z})\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatrix_exp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43mj\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mparam\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mP\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mP\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "t0 = tpc()\n",
    "res = run_single_training(config=CFG, verbose=True, seed=42)\n",
    "t1 = tpc()\n",
    "print(f'Runtime = {t1-t0}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5fab75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in SINGLE RUN mode.\n",
      "\n",
      "\n",
      "================================================== \n",
      "run_timestamp: 2025-07-24__18-03-10,\n",
      "----------------------------------------------\n",
      "load_timestamp: None,\n",
      "type_of_warm_start: none,\n",
      "warm_start_strength: 0.1,\n",
      "----------------------------------------------\n",
      "system_size: 3,\n",
      "extra_ancilla: False,\n",
      "ancilla_mode: pass,\n",
      "ancilla_project_norm: re-norm,\n",
      "ancilla_topology: bridge,\n",
      "ancilla_connect_to: None,\n",
      "do_ancilla_1q_gates: False,\n",
      "start_ancilla_gates_randomly: False,\n",
      "----------------------------------------------\n",
      "gen_layers: 3,\n",
      "gen_ansatz: ZZ_X_Z,\n",
      "----------------------------------------------\n",
      "target_hamiltonian: custom_h,\n",
      "custom_hamiltonian_terms: ['XZ', 'X'],\n",
      "custom_hamiltonian_strengths: [1.0, 0.1],\n",
      "----------------------------------------------\n",
      "epochs: 10,\n",
      "iterations_epoch: 300,\n",
      "log_every_x_iter: 10,\n",
      "save_fid_and_loss_every_x_iter: 1,\n",
      "max_fidelity: 0.99,\n",
      "steps_gen: 1,\n",
      "steps_dis: 1,\n",
      "----------------------------------------------\n",
      "l_rate: 0.01,\n",
      "momentum_coeff: 0.9,\n",
      "================================================== \n",
      "\n",
      "\n",
      "Starting training from scratch (no timestamp specified).\n",
      "\n",
      "==================================================\n",
      "\n",
      "\n",
      "epoch:   1 | iters:   1 | fidelity:0.005456 | loss:-3.744550\n",
      "\n",
      "epoch:   1 | iters:  11 | fidelity:0.006036 | loss:-3.428219\n",
      "\n",
      "epoch:   1 | iters:  21 | fidelity:0.007139 | loss:-3.085855\n",
      "\n",
      "epoch:   1 | iters:  31 | fidelity:0.008729 | loss:-2.775744\n",
      "\n",
      "epoch:   1 | iters:  41 | fidelity:0.010137 | loss:-2.543284\n",
      "\n",
      "epoch:   1 | iters:  51 | fidelity:0.008866 | loss:-2.318953\n",
      "\n",
      "epoch:   1 | iters:  61 | fidelity:0.009406 | loss:-1.522095\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 2\u001b[39m\n",
      "\u001b[32m      1\u001b[39m t0 = tpc()\n",
      "\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m res = \u001b[43mrun_single_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCFG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m      3\u001b[39m t1 = tpc()\n",
      "\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mRuntime = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt1-t0\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\tools\\training_init.py:47\u001b[39m, in \u001b[36mrun_single_training\u001b[39m\u001b[34m(config, verbose, seed)\u001b[39m\n",
      "\u001b[32m     42\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[32m     43\u001b[39m     \u001b[38;5;66;03m##############################################################\u001b[39;00m\n",
      "\u001b[32m     44\u001b[39m     \u001b[38;5;66;03m# Run single training instance with specified configuration\u001b[39;00m\n",
      "\u001b[32m     45\u001b[39m     \u001b[38;5;66;03m##############################################################\u001b[39;00m\n",
      "\u001b[32m     46\u001b[39m     training_instance = Training(config=config, verbose=verbose, seed=seed)\n",
      "\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     res = \u001b[43mtraining_instance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m     48\u001b[39m     success_msg = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mDefault configuration run COMPLETED SUCCESSFULLY.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n",
      "\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\qgan\\training.py:90\u001b[39m, in \u001b[36mTraining.run\u001b[39m\u001b[34m(self)\u001b[39m\n",
      "\u001b[32m     85\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch_iter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.config.iterations_epoch):\n",
      "\u001b[32m     86\u001b[39m     \u001b[38;5;66;03m###########################################################\u001b[39;00m\n",
      "\u001b[32m     87\u001b[39m     \u001b[38;5;66;03m# Gen and Dis gradient descent\u001b[39;00m\n",
      "\u001b[32m     88\u001b[39m     \u001b[38;5;66;03m###########################################################\u001b[39;00m\n",
      "\u001b[32m     89\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.config.steps_gen):\n",
      "\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate_gen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfinal_target_state\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m     92\u001b[39m     \u001b[38;5;66;03m# Remove ancilla if needed, with ancilla mode, before discriminator:\u001b[39;00m\n",
      "\u001b[32m     93\u001b[39m     final_gen_state = get_final_gen_state_for_discriminator(\u001b[38;5;28mself\u001b[39m.gen.total_gen_state)\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\qgan\\generator.py:90\u001b[39m, in \u001b[36mupdate_gen\u001b[39m\u001b[34m(self, dis, final_target_state)\u001b[39m\n",
      "\u001b[32m     88\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.extra_ancilla:\n",
      "\u001b[32m     89\u001b[39m     ancilla_q = system_qubits\n",
      "\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.ancilla_topology == \u001b[33m\"\u001b[39m\u001b[33mtotal\u001b[39m\u001b[33m\"\u001b[39m:\n",
      "\u001b[32m     91\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(system_qubits):\n",
      "\u001b[32m     92\u001b[39m             qc.add_gate(QuantumGate(\u001b[33m\"\u001b[39m\u001b[33mZZ\u001b[39m\u001b[33m\"\u001b[39m, i, ancilla_q, angle=\u001b[32m0.0\u001b[39m))\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\qgan\\generator.py:146\u001b[39m, in \u001b[36m_grad_theta\u001b[39m\u001b[34m(self, dis, final_target_state, total_gen_state)\u001b[39m\n",
      "\u001b[32m    143\u001b[39m     total_gen_state = torch.matmul(full_op, total_input_state)\n",
      "\u001b[32m    144\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m total_gen_state\n",
      "\u001b[32m--> \u001b[39m\u001b[32m146\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mload_model_params\u001b[39m(\u001b[38;5;28mself\u001b[39m, file_path: \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[32m    147\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Loads generator parameters from a saved state_dict.\"\"\"\u001b[39;00m\n",
      "\u001b[32m    148\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[32m    149\u001b[39m         \u001b[38;5;66;03m# Load the entire saved dictionary, which includes config\u001b[39;00m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\qgan\\generator.py:77\u001b[39m, in \u001b[36mget_total_gen_grad\u001b[39m\u001b[34m(self, index)\u001b[39m\n",
      "\u001b[32m     74\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconstruct_qcircuit_ZZ_X_Z\u001b[39m(\u001b[38;5;28mself\u001b[39m, qc: QuantumCircuit, size: \u001b[38;5;28mint\u001b[39m, layer: \u001b[38;5;28mint\u001b[39m):\n",
      "\u001b[32m     75\u001b[39m     system_qubits = size - \u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.config.extra_ancilla \u001b[38;5;28;01melse\u001b[39;00m size\n",
      "\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(layer):\n",
      "\u001b[32m     78\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(system_qubits):\n",
      "\u001b[32m     79\u001b[39m             qc.add_gate(QuantumGate(\u001b[33m\"\u001b[39m\u001b[33mX\u001b[39m\u001b[33m\"\u001b[39m, i, angle=\u001b[32m0.0\u001b[39m))\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\tools\\qobjects\\qcircuit.py:69\u001b[39m, in \u001b[36mget_grad_mat_rep\u001b[39m\u001b[34m(self, index, signal, type)\u001b[39m\n",
      "\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\tools\\qobjects\\qgates.py:262\u001b[39m, in \u001b[36mmatrix_representation\u001b[39m\u001b[34m(self, size, is_grad)\u001b[39m\n",
      "\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\tools\\qobjects\\qgates.py:167\u001b[39m, in \u001b[36mZZ_Rotation\u001b[39m\u001b[34m(size, qubit1, qubit2, param, is_grad)\u001b[39m\n",
      "\u001b[32m      0\u001b[39m <Error retrieving source code with stack_data see ipython/ipython#13598>\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\f52ga\\miniforge3\\envs\\qgan\\Lib\\site-packages\\scipy\\linalg\\_matfuncs.py:338\u001b[39m, in \u001b[36mexpm\u001b[39m\u001b[34m(A)\u001b[39m\n",
      "\u001b[32m    336\u001b[39m lu = bandwidth(aw)\n",
      "\u001b[32m    337\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28many\u001b[39m(lu):  \u001b[38;5;66;03m# a is diagonal?\u001b[39;00m\n",
      "\u001b[32m--> \u001b[39m\u001b[32m338\u001b[39m     eA[ind] = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdiag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdiag\u001b[49m\u001b[43m(\u001b[49m\u001b[43maw\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    339\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n",
      "\u001b[32m    341\u001b[39m \u001b[38;5;66;03m# Generic/triangular case; copy the slice into scratch and send.\u001b[39;00m\n",
      "\u001b[32m    342\u001b[39m \u001b[38;5;66;03m# Am will be mutated by pick_pade_structure\u001b[39;00m\n",
      "\u001b[32m    343\u001b[39m \u001b[38;5;66;03m# If s != 0, scaled Am will be returned from pick_pade_structure.\u001b[39;00m\n",
      "\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\f52ga\\miniforge3\\envs\\qgan\\Lib\\site-packages\\numpy\\lib\\_twodim_base_impl.py:318\u001b[39m, in \u001b[36mdiag\u001b[39m\u001b[34m(v, k)\u001b[39m\n",
      "\u001b[32m    316\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(s) == \u001b[32m1\u001b[39m:\n",
      "\u001b[32m    317\u001b[39m     n = s[\u001b[32m0\u001b[39m] + \u001b[38;5;28mabs\u001b[39m(k)\n",
      "\u001b[32m--> \u001b[39m\u001b[32m318\u001b[39m     res = \u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[32m    319\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m k >= \u001b[32m0\u001b[39m:\n",
      "\u001b[32m    320\u001b[39m         i = k\n",
      "\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "t0 = tpc()\n",
    "res = run_single_training(config=CFG, verbose=True, seed=42)\n",
    "t1 = tpc()\n",
    "print(f'Runtime = {t1-t0}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69cf06b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Runtime = 0.45385289983823895s\n",
      "(array([-3.35849634, -3.33873448, -3.310137  , -3.27325934, -3.22865898,\n",
      "       -3.17694117, -3.11876826, -3.05483983, -2.98585487, -2.9124685 ,\n",
      "       -2.83525292, -2.75466855, -2.67104708, -2.58458568, -2.49535167,\n",
      "       -2.40330142, -2.30832592, -2.21034934, -2.10952355, -2.00657244]), array([0.0125486 , 0.0124631 , 0.01234333, 0.01219449, 0.01202085,\n",
      "       0.01182533, 0.01160938, 0.01137297, 0.01111466, 0.0108319 ,\n",
      "       0.01052127, 0.01017883, 0.00980058, 0.00938297, 0.00892355,\n",
      "       0.00842173, 0.0078797 , 0.00730332, 0.00670295, 0.00609391]))\n"
     ]
    }
   ],
   "source": [
    "t0 = tpc()\n",
    "res = run_single_training(config=config, verbose=False, seed=42)\n",
    "t1 = tpc()\n",
    "print(f'Runtime = {t1-t0}s')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "07bb400d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203 ms ± 9.37 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit run_single_training(config=config, verbose=False, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "09f97fce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tools.training_init\n",
    "import qgan.cost_functions\n",
    "from qgan.training import Training\n",
    "from qgan.generator import Generator\n",
    "from qgan.discriminator import Discriminator\n",
    "from tools.qobjects.qcircuit import QuantumCircuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0234e319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4c1c7185",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(16, 16) (16, 16) (16, 16)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\f52ga\\miniforge3\\envs\\qgan\\Lib\\site-packages\\line_profiler\\ipython_extension.py:97: UserWarning: Could not extract a code object for the object <class 'qgan.discriminator.Discriminator'>\n",
      "  profile = LineProfiler(*funcs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(16, 16) (16, 16) (16, 16)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(16, 16) (16, 16) (16, 16)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(16, 16) (16, 16) (16, 16)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(16, 16) (16, 16) (16, 16)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(16, 16) (16, 16) (16, 16)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(16, 16) (16, 16) (16, 16)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(16, 16) (16, 16) (16, 16)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(16, 16) (16, 16) (16, 16)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(16, 16) (16, 16) (16, 16)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(16, 16) (16, 16) (16, 16)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(16, 16) (16, 16) (16, 16)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(16, 16) (16, 16) (16, 16)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(16, 16) (16, 16) (16, 16)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(16, 16) (16, 16) (16, 16)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(16, 16) (16, 16) (16, 16)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(16, 16) (16, 16) (16, 16)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(16, 16) (16, 16) (16, 16)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(16, 16) (16, 16) (16, 16)\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "(16, 16) (16, 16) (16, 16)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-07 s\n",
      "\n",
      "Total time: 6.25157 s\n",
      "File: c:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\qgan\\discriminator.py\n",
      "Function: update_dis at line 121\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   121                                               def update_dis(self, final_target_state: np.ndarray, final_gen_state: np.ndarray):\n",
      "   122                                                   \"\"\"Update the discriminator parameters (alpha, beta) using the gradients.\n",
      "   123                                           \n",
      "   124                                                   Args:\n",
      "   125                                                       final_target_state (np.ndarray): The final target state of the system.\n",
      "   126                                                       final_gen_state (np.ndarray): The final gen state of the system.\n",
      "   127                                                   \"\"\"\n",
      "   128                                                   ################################################################\n",
      "   129                                                   # Get the current Discriminator state:\n",
      "   130                                                   ################################################################\n",
      "   131        20   11368561.0 568428.1     18.2          A, B, _, _ = self.get_dis_matrices_rep()\n",
      "   132                                           \n",
      "   133                                                   ####################################################\n",
      "   134                                                   # Update alpha\n",
      "   135                                                   ####################################################\n",
      "   136        20   25674272.0    1e+06     41.1          grad_alpha = self._compute_grad(final_target_state, final_gen_state, A, B, \"alpha\")\n",
      "   137        20      40704.0   2035.2      0.1          new_alpha = self.optimizer_psi.move_in_grad(self.alpha, grad_alpha, \"max\")\n",
      "   138                                           \n",
      "   139                                                   ####################################################\n",
      "   140                                                   # Update beta\n",
      "   141                                                   ####################################################\n",
      "   142        20   25384359.0    1e+06     40.6          grad_beta = self._compute_grad(final_target_state, final_gen_state, A, B, \"beta\")\n",
      "   143        20      47287.0   2364.3      0.1          new_beta = self.optimizer_phi.move_in_grad(self.beta, grad_beta, \"max\")\n",
      "   144                                           \n",
      "   145                                                   # Update the parameters later, to avoid affecting gradient computations:\n",
      "   146        20        321.0     16.1      0.0          self.alpha = new_alpha\n",
      "   147        20        183.0      9.2      0.0          self.beta = new_beta\n",
      "\n",
      "Total time: 5.10494 s\n",
      "File: c:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\qgan\\discriminator.py\n",
      "Function: _compute_grad at line 149\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   149                                               def _compute_grad(self, final_target_state, final_gen_state, A, B, param: str) -> np.ndarray:\n",
      "   150                                                   \"\"\"Calculate the gradient of the discriminator with respect to the param (alpha or beta).\n",
      "   151                                           \n",
      "   152                                                   Args:\n",
      "   153                                                       final_target_state (np.ndarray): The final target state of the system.\n",
      "   154                                                       final_gen_state (np.ndarray): The final gen state of the system.\n",
      "   155                                                       A (np.ndarray): expm(-1/lamb * phi), with phi being the matrix repr. of the imag part of the dis.\n",
      "   156                                                       B (np.ndarray): expm(1/lamb * psi), with psi being the matrix repr. of the real part of the dis.\n",
      "   157                                                       param (str): The parameter to compute the gradient for (\"alpha\" or \"beta\").\n",
      "   158                                           \n",
      "   159                                                   Returns:\n",
      "   160                                                       np.ndarray: The gradient of the discriminator with respect to beta.\n",
      "   161                                                   \"\"\"\n",
      "   162                                                   ################################################################\n",
      "   163                                                   # Initialize gradients on 0:\n",
      "   164                                                   #################################################################\n",
      "   165        40        455.0     11.4      0.0          zero_param = self.alpha if param == \"alpha\" else self.beta\n",
      "   166        40       6603.0    165.1      0.0          grad_psi_term = np.zeros_like(zero_param, dtype=complex)\n",
      "   167        40       3229.0     80.7      0.0          grad_phi_term = np.zeros_like(zero_param, dtype=complex)\n",
      "   168        40       2877.0     71.9      0.0          grad_reg_term = np.zeros_like(zero_param, dtype=complex)\n",
      "   169                                           \n",
      "   170       200       1614.0      8.1      0.0          for type in range(len(self.herm)):\n",
      "   171                                                       ###########################################################\n",
      "   172                                                       # Compute the alpha or beta gradient step:\n",
      "   173                                                       ############################################################\n",
      "   174       160       2151.0     13.4      0.0              grad_step = self._grad_alpha if param == \"alpha\" else self._grad_beta if param == \"beta\" else None\n",
      "   175       160   51006628.0 318791.4     99.9              gradpsi_list, gradphi_list, gradreg_list = grad_step(final_target_state, final_gen_state, A, B, type)\n",
      "   176                                           \n",
      "   177                                                       # Add grad of psi, phi and reg terms\n",
      "   178       160      11833.0     74.0      0.0              grad_psi_term[:, type] = np.asarray(gradpsi_list)\n",
      "   179       160       6034.0     37.7      0.0              grad_phi_term[:, type] = np.asarray(gradphi_list)\n",
      "   180       160       3502.0     21.9      0.0              grad_reg_term[:, type] = np.asarray(gradreg_list)\n",
      "   181                                           \n",
      "   182        40       4161.0    104.0      0.0          grad = np.real(grad_psi_term - grad_phi_term - grad_reg_term)\n",
      "   183                                           \n",
      "   184        40        306.0      7.7      0.0          return np.asarray(grad)\n",
      "\n",
      "Total time: 2.5624 s\n",
      "File: c:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\qgan\\discriminator.py\n",
      "Function: _grad_alpha at line 186\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   186                                               def _grad_alpha(self, final_target_state, final_gen_state, A: np.ndarray, B: np.ndarray, op_type: str) -> np.ndarray:\n",
      "   187                                                   \"\"\"Calculate a step of the gradient of the discriminator with respect to alpha.\n",
      "   188                                           \n",
      "   189                                                   Args:\n",
      "   190                                                       final_target_state (np.ndarray): The final target state of the system.\n",
      "   191                                                       final_gen_state (np.ndarray): The final gen state of the system.\n",
      "   192                                                       A (np.ndarray): expm(-1/lamb * phi), with phi being the matrix repr. of the imag part of the dis.\n",
      "   193                                                       B (np.ndarray): expm(1/lamb * psi), with psi being the matrix repr. of the real part of the dis.\n",
      "   194                                                       type (str): The type of hermitian operator (0: I, 1: X, 2: Y, 3: Z).\n",
      "   195                                           \n",
      "   196                                                   Returns:\n",
      "   197                                                       tuple: A tuple containing the gradients of psi, phi, and regularization terms.\n",
      "   198                                                   \"\"\"\n",
      "   199        80       1016.0     12.7      0.0          cs = 1 / lamb\n",
      "   200                                           \n",
      "   201        80   25275641.0 315945.5     98.6          gradpsi: list = self._grad_psi_or_phi(op_type, respect_to=\"psi\")\n",
      "   202        80        564.0      7.0      0.0          gradpsi_list, gradphi_list, gradreg_list = [], [], []\n",
      "   203                                           \n",
      "   204        80      18235.0    227.9      0.1          A_final_gen_state = A @ final_gen_state\n",
      "   205        80       3640.0     45.5      0.0          B_final_gen_state = B @ final_gen_state\n",
      "   206        80       2033.0     25.4      0.0          A_final_target_state = A @ final_target_state\n",
      "   207        80       1743.0     21.8      0.0          B_final_target_state = B @ final_target_state\n",
      "   208                                           \n",
      "   209        80       7984.0     99.8      0.0          exp_A_final_gen_state = np.vdot(final_gen_state, A_final_gen_state)\n",
      "   210        80       2478.0     31.0      0.0          exp_A_final_target_state = np.vdot(final_target_state, A_final_target_state)\n",
      "   211        80       1971.0     24.6      0.0          exp_A_final_gen_target_state =  np.vdot(final_gen_state, A_final_target_state)\n",
      "   212        80       1899.0     23.7      0.0          exp_A_final_target_gen_state =  np.vdot(final_target_state, A_final_gen_state)\n",
      "   213                                           \n",
      "   214                                                   # fmt: off\n",
      "   215       400       2394.0      6.0      0.0          for grad_psi in gradpsi:\n",
      "   216                                                       ##################################################################\n",
      "   217                                                       # Compute the gradient of psi with respect to alpha\n",
      "   218                                                       ##################################################################\n",
      "   219       320     102652.0    320.8      0.4              gradpsi_list.append(np.vdot(final_target_state, grad_psi @ final_target_state))\n",
      "   220                                           \n",
      "   221                                                       ##################################################################\n",
      "   222                                                       # No gradient of phi with respect to alpha, so append 0\n",
      "   223                                                       ##################################################################\n",
      "   224       320       1462.0      4.6      0.0              gradphi_list.append(0)\n",
      "   225                                           \n",
      "   226                                                       ##################################################################\n",
      "   227                                                       # Compute the regularization terms:\n",
      "   228                                                       ##################################################################\n",
      "   229       320      67863.0    212.1      0.3              grad_psi_B_final_target_state = grad_psi @ B_final_target_state\n",
      "   230       320      85728.0    267.9      0.3              grad_psi_B_final_gen_state = grad_psi @ B_final_gen_state\n",
      "   231       320      12089.0     37.8      0.0              term1 = cs * exp_A_final_gen_state * np.vdot(final_target_state, grad_psi_B_final_target_state)\n",
      "   232       320       8735.0     27.3      0.0              term2 = cs * np.vdot(final_gen_state, grad_psi_B_final_target_state) * exp_A_final_target_gen_state\n",
      "   233       320       8719.0     27.2      0.0              term3 = cs * exp_A_final_gen_target_state * np.vdot(final_target_state, grad_psi_B_final_gen_state)\n",
      "   234       320       8247.0     25.8      0.0              term4 = cs * np.vdot(final_gen_state, grad_psi_B_final_gen_state) * exp_A_final_target_state\n",
      "   235       320       8447.0     26.4      0.0              gradreg_list.append(lamb / np.e * (cst1 * term1 - cst2 * (term2 + term3) + cst3 * term4))\n",
      "   236                                                   # fmt: on\n",
      "   237                                           \n",
      "   238        80        450.0      5.6      0.0          return gradpsi_list, gradphi_list, gradreg_list\n",
      "\n",
      "Total time: 2.53291 s\n",
      "File: c:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\qgan\\discriminator.py\n",
      "Function: _grad_beta at line 240\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   240                                               def _grad_beta(self, final_target_state, final_gen_state, A: np.ndarray, B: np.ndarray, type: str):\n",
      "   241                                                   \"\"\"Calculate a step of the gradient of the discriminator with respect to beta.\n",
      "   242                                           \n",
      "   243                                                   Args:\n",
      "   244                                                       final_target_state (np.ndarray): The final target state of the system.\n",
      "   245                                                       final_gen_state (np.ndarray): The final gen state of the system.\n",
      "   246                                                       A (np.ndarray): expm(-1/lamb * phi), with phi being the matrix repr. of the imag part of the dis.\n",
      "   247                                                       B (np.ndarray): expm(1/lamb * psi), with psi being the matrix repr. of the real part of the dis.\n",
      "   248                                                       type (str): The type of hermitian operator (0: I, 1: X, 2: Y, 3: Z).\n",
      "   249                                           \n",
      "   250                                                   Returns:\n",
      "   251                                                       tuple: A tuple containing the gradients of psi, phi, and regularization terms.\n",
      "   252                                                   \"\"\"\n",
      "   253        80       1080.0     13.5      0.0          cs = -1 / lamb\n",
      "   254                                           \n",
      "   255        80   24927247.0 311590.6     98.4          gradphi: list = self._grad_psi_or_phi(type, respect_to=\"phi\")\n",
      "   256        80        573.0      7.2      0.0          gradpsi_list, gradphi_list, gradreg_list = [], [], []\n",
      "   257                                           \n",
      "   258        80      14037.0    175.5      0.1          A_final_gen_state = A @ final_gen_state\n",
      "   259        80       3970.0     49.6      0.0          B_final_gen_state = B @ final_gen_state\n",
      "   260        80       2260.0     28.2      0.0          A_final_target_state = A @ final_target_state\n",
      "   261        80       1977.0     24.7      0.0          B_final_target_state = B @ final_target_state\n",
      "   262                                           \n",
      "   263        80       7607.0     95.1      0.0          exp_B_final_gen_state = np.vdot(final_gen_state, B_final_gen_state)\n",
      "   264        80       2602.0     32.5      0.0          exp_B_final_target_state = np.vdot(final_target_state, B_final_target_state)\n",
      "   265        80       2077.0     26.0      0.0          exp_B_final_gen_target_state =  np.vdot(final_gen_state, B_final_target_state)\n",
      "   266        80       1991.0     24.9      0.0          exp_B_final_target_gen_state =  np.vdot(final_target_state, B_final_gen_state)\n",
      "   267                                           \n",
      "   268                                                   # fmt: off\n",
      "   269       400       2710.0      6.8      0.0          for grad_phi in gradphi:\n",
      "   270                                                       ##################################################################\n",
      "   271                                                       # No gradient of psi with respect to beta, so append 0\n",
      "   272                                                       ##################################################################\n",
      "   273       320       1660.0      5.2      0.0              gradpsi_list.append(0)\n",
      "   274                                           \n",
      "   275                                                       ##################################################################\n",
      "   276                                                       # Compute the gradient of phi with respect to beta\n",
      "   277                                                       ##################################################################\n",
      "   278       320     116653.0    364.5      0.5              gradphi_list.append(np.vdot(final_gen_state, grad_phi @ final_gen_state))\n",
      "   279                                           \n",
      "   280                                                       ##################################################################\n",
      "   281                                                       # Compute the regularization terms:\n",
      "   282                                                       ##################################################################\n",
      "   283       320      82243.0    257.0      0.3              grad_phi_A_final_target_state = grad_phi @ A_final_target_state\n",
      "   284       320     104361.0    326.1      0.4              grad_phi_A_final_gen_state = grad_phi @ A_final_gen_state\n",
      "   285       320      15848.0     49.5      0.1              term1 = cs * np.vdot(final_gen_state, grad_phi_A_final_gen_state) * exp_B_final_target_state\n",
      "   286       320      10314.0     32.2      0.0              term2 = cs * exp_B_final_gen_target_state * np.vdot(final_target_state, grad_phi_A_final_gen_state)\n",
      "   287       320       9966.0     31.1      0.0              term3 = cs * np.vdot(final_gen_state, grad_phi_A_final_target_state) * exp_B_final_target_gen_state\n",
      "   288       320       9636.0     30.1      0.0              term4 = cs * exp_B_final_gen_state * np.vdot(final_target_state, grad_phi_A_final_target_state)\n",
      "   289       320       9758.0     30.5      0.0              gradreg_list.append(lamb / np.e * (cst1 * term1 - cst2 * (term2 + term3) + cst3 * term4))\n",
      "   290                                                   # fmt: on\n",
      "   291                                           \n",
      "   292        80        490.0      6.1      0.0          return gradpsi_list, gradphi_list, gradreg_list\n",
      "\n",
      "Total time: 5.00359 s\n",
      "File: c:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\qgan\\discriminator.py\n",
      "Function: _grad_psi_or_phi at line 295\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   295                                               def _grad_psi_or_phi(self, type: int, respect_to: str) -> list:\n",
      "   296                                                   \"\"\"Calculate the gradient of the discriminator with respect to psi or phi (sparse).\n",
      "   297                                           \n",
      "   298                                                   Args:\n",
      "   299                                                       type (int): The type of Hermitian operator (0: I, 1: X, 2: Y, 3: Z).\n",
      "   300                                                       respect_to (str): Specify whether to compute the gradient for psi or phi.\n",
      "   301                                           \n",
      "   302                                                   Returns:\n",
      "   303                                                       list: A list of sparse gradients for each qubit in the discriminator.\n",
      "   304                                                   \"\"\"\n",
      "   305       160       1334.0      8.3      0.0          coefficients = self.alpha if respect_to == \"psi\" else self.beta\n",
      "   306       160        707.0      4.4      0.0          grad_matrix = []\n",
      "   307                                           \n",
      "   308       800       5909.0      7.4      0.0          for i in range(self.size):\n",
      "   309       640    1644268.0   2569.2      3.3              grad_matrix_I = csr_matrix([[1]])  # Start with 1 as a 1x1 sparse matrix\n",
      "   310      3200      25484.0      8.0      0.1              for j in range(self.size):\n",
      "   311      2560      11043.0      4.3      0.0                  if i == j:\n",
      "   312       640       6562.0     10.3      0.0                      grad_matrix_j = self.herm[type]  # Already assumed to be sparse\n",
      "   313                                                           else:\n",
      "   314                                                               # Start with a sparse zero matrix of the same shape\n",
      "   315      1920    2024727.0   1054.5      4.0                      grad_matrix_j = csr_matrix(self.herm[0].shape, dtype=complex)\n",
      "   316      9600      64098.0      6.7      0.1                      for k, herm_k in enumerate(self.herm):\n",
      "   317      7680   22622801.0   2945.7     45.2                          grad_matrix_j += coefficients[j][k] * herm_k\n",
      "   318      2560   23624092.0   9228.2     47.2                  grad_matrix_I = kron(grad_matrix_I, grad_matrix_j, format='csr')\n",
      "   319       640       4066.0      6.4      0.0              grad_matrix.append(grad_matrix_I)\n",
      "   320                                           \n",
      "   321       160        810.0      5.1      0.0          return grad_matrix\n",
      "\n",
      "Total time: 0.134214 s\n",
      "File: c:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\qgan\\generator.py\n",
      "Function: get_total_gen_grad at line 68\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    68                                               def get_total_gen_grad(self, index) -> np.ndarray:\n",
      "    69                                                   \"\"\"Get the total generator gradient for a specific gate index.\n",
      "    70                                           \n",
      "    71                                                   Args:\n",
      "    72                                                       index (int): The index of the gate for which to compute the gradient.\n",
      "    73                                           \n",
      "    74                                                   Returns:\n",
      "    75                                                       np.ndarray: The total generator gradient vector for the specified gate.\n",
      "    76                                                   \"\"\"\n",
      "    77       100    1337858.0  13378.6     99.7          Untouched_x_G_grad_i = np.kron(np.eye(2**self.config.system_size), self.qc.get_grad_mat_rep(index))\n",
      "    78       100       4283.0     42.8      0.3          return np.matmul(Untouched_x_G_grad_i, self.total_input_state)\n",
      "\n",
      "Total time: 1.28766 s\n",
      "File: c:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\qgan\\generator.py\n",
      "Function: update_gen at line 80\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    80                                               def update_gen(self, dis: Discriminator, final_target_state: np.ndarray):\n",
      "    81                                                   \"\"\"Update the generator parameters (angles) using the optimizer.\n",
      "    82                                           \n",
      "    83                                                   Args:\n",
      "    84                                                       dis (Discriminator): The discriminator to compute gradients.\n",
      "    85                                                       final_target_state (np.ndarray): The target state vector.\n",
      "    86                                                   \"\"\"\n",
      "    87                                                   ###############################################################\n",
      "    88                                                   # Compute the gradient\n",
      "    89                                                   ###############################################################\n",
      "    90        20   12603117.0 630155.8     97.9          grad: np.ndarray = self._grad_theta(dis, final_target_state, self.total_gen_state)\n",
      "    91                                           \n",
      "    92                                                   # Get the new thetas from the gradient\n",
      "    93       120       1281.0     10.7      0.0          theta = np.asarray([gate.angle for gate in self.qc.gates])\n",
      "    94        20      13315.0    665.8      0.1          new_theta = self.optimizer.move_in_grad(theta, grad, \"min\")\n",
      "    95                                           \n",
      "    96                                                   ###############################################################\n",
      "    97                                                   # Update the angles in the quantum circuit\n",
      "    98                                                   ###############################################################\n",
      "    99       120        708.0      5.9      0.0          for i in range(self.qc.depth):\n",
      "   100       100        651.0      6.5      0.0              self.qc.gates[i].angle = new_theta[i]\n",
      "   101                                           \n",
      "   102                                                   ###############################################################\n",
      "   103                                                   # Update the total generator state with the new angles\n",
      "   104                                                   ###############################################################\n",
      "   105        20     257560.0  12878.0      2.0          self.total_gen_state = self.get_total_gen_state()\n",
      "\n",
      "Total time: 1.25906 s\n",
      "File: c:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\qgan\\generator.py\n",
      "Function: _grad_theta at line 107\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "   107                                               def _grad_theta(\n",
      "   108                                                   self,\n",
      "   109                                                   dis: Discriminator,\n",
      "   110                                                   final_target_state: np.ndarray,\n",
      "   111                                                   total_gen_state: np.ndarray,\n",
      "   112                                               ) -> np.ndarray:\n",
      "   113                                                   \"\"\"Compute the gradient of the generator parameters (angles) with respect to the discriminator's output.\n",
      "   114                                           \n",
      "   115                                                   Args:\n",
      "   116                                                       dis (Discriminator): The discriminator to compute gradients.\n",
      "   117                                                       final_target_state (np.ndarray): The target state vector.\n",
      "   118                                                       total_gen_state (np.ndarray): The current generator state vector.\n",
      "   119                                           \n",
      "   120                                                   Returns:\n",
      "   121                                                       np.ndarray: The gradient of the generator parameters.\n",
      "   122                                                   \"\"\"\n",
      "   123                                                   #######################################################################\n",
      "   124                                                   # Get the current Generator, Target and Discriminator states:\n",
      "   125                                                   #######################################################################\n",
      "   126        20        690.0     34.5      0.0          final_gen_state = get_final_gen_state_for_discriminator(total_gen_state)\n",
      "   127        20   11091501.0 554575.1     88.1          A, B, _, phi = dis.get_dis_matrices_rep()\n",
      "   128                                           \n",
      "   129        20      64516.0   3225.8      0.5          print(type(A), type(B), type(phi))\n",
      "   130        20      33773.0   1688.7      0.3          print(A.shape, B.shape, phi.shape)\n",
      "   131                                           \n",
      "   132        20        120.0      6.0      0.0          grad_g_psi, grad_g_phi, grad_g_reg = [], [], []\n",
      "   133        20       3402.0    170.1      0.0          A_final_target_state = A @ final_target_state\n",
      "   134        20        638.0     31.9      0.0          B_final_target_state = B @ final_target_state\n",
      "   135        20        508.0     25.4      0.0          A_final_gen_state = A @ final_gen_state\n",
      "   136        20        451.0     22.6      0.0          B_final_gen_state = B @ final_gen_state\n",
      "   137        20        579.0     28.9      0.0          phi_final_gen_state = phi @ final_gen_state\n",
      "   138        20       2097.0    104.8      0.0          exp_final_target_A = np.vdot(final_target_state, A_final_target_state)\n",
      "   139        20        562.0     28.1      0.0          exp_final_target_B = np.vdot(final_target_state, B_final_target_state)\n",
      "   140        20        513.0     25.6      0.0          exp_final_gen_target_A = np.vdot(final_gen_state, A_final_target_state)\n",
      "   141        20        488.0     24.4      0.0          exp_final_gen_target_B = np.vdot(final_gen_state, B_final_target_state)\n",
      "   142                                                   \n",
      "   143       120       1209.0     10.1      0.0          for i in range(self.qc.depth):\n",
      "   144                                                       # fmt: off\n",
      "   145                                                       # For psi term\n",
      "   146       100        524.0      5.2      0.0              grad_g_psi.append(0)\n",
      "   147                                           \n",
      "   148                                                       # For phi term\n",
      "   149       100    1345586.0  13455.9     10.7              total_gen_grad = self.get_total_gen_grad(i)\n",
      "   150       100       2622.0     26.2      0.0              final_gen_grad = get_final_gen_state_for_discriminator(total_gen_grad)\n",
      "   151                                                       \n",
      "   152       100       6857.0     68.6      0.1              tmp_grad = np.vdot(final_gen_grad, phi_final_gen_state) + np.vdot(phi_final_gen_state, final_gen_grad)\n",
      "   153       100        591.0      5.9      0.0              grad_g_phi.append(tmp_grad)\n",
      "   154                                           \n",
      "   155                                                       # For reg term\n",
      "   156       100       3027.0     30.3      0.0              term1 = np.vdot(final_gen_grad, A_final_gen_state) * exp_final_target_B\n",
      "   157       100       2562.0     25.6      0.0              term2 = np.vdot(A_final_gen_state, final_gen_grad) * exp_final_target_B\n",
      "   158       100       4728.0     47.3      0.0              term3 = np.vdot(final_gen_grad, B_final_target_state) * np.vdot(A_final_target_state, final_gen_state)\n",
      "   159       100       3142.0     31.4      0.0              term4 = exp_final_gen_target_B * np.vdot(A_final_target_state, final_gen_grad)\n",
      "   160       100       4554.0     45.5      0.0              term5 = np.vdot(final_gen_grad, A_final_target_state) * np.vdot(B_final_target_state, final_gen_state)\n",
      "   161       100       2477.0     24.8      0.0              term6 = exp_final_gen_target_A * np.vdot(B_final_target_state, final_gen_grad)\n",
      "   162       100       2425.0     24.2      0.0              term7 = np.vdot(final_gen_grad, B_final_gen_state) * exp_final_target_A\n",
      "   163       100       2401.0     24.0      0.0              term8 = np.vdot(B_final_gen_state, final_gen_grad) * exp_final_target_A\n",
      "   164       100       4017.0     40.2      0.0              tmp_reg_grad = self.config.lamb / np.e * (self.config.cst1 * (term1 + term2) - self.config.cst2 * (term3 + term4 + term5 + term6) + self.config.cst3 * (term7 + term8))\n",
      "   165       100        514.0      5.1      0.0              grad_g_reg.append(tmp_reg_grad)\n",
      "   166                                                       # fmt: on\n",
      "   167                                           \n",
      "   168        20        445.0     22.2      0.0          g_psi = np.asarray(grad_g_psi)\n",
      "   169        20        440.0     22.0      0.0          g_phi = np.asarray(grad_g_phi)\n",
      "   170        20        270.0     13.5      0.0          g_reg = np.asarray(grad_g_reg)\n",
      "   171                                           \n",
      "   172        20       2186.0    109.3      0.0          grad = np.real(g_psi - g_phi - g_reg)\n",
      "   173                                                   \n",
      "   174        20        137.0      6.8      0.0          return np.asarray(grad)\n",
      "\n",
      "Total time: 8.66561 s\n",
      "File: c:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\qgan\\training.py\n",
      "Function: run at line 61\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    61                                               def run(self):\n",
      "    62                                                   \"\"\"Run the training, saving the data, the model, the logs, and the results plots.\"\"\"\n",
      "    63                                           \n",
      "    64                                                   ###########################################################\n",
      "    65                                                   # Initialize training\n",
      "    66                                                   ###########################################################\n",
      "    67         1          6.0      6.0      0.0          if self.verbose:\n",
      "    68                                                       print_and_log(\"\\n\" + self.config.show_data(), self.config.log_path)\n",
      "    69                                           \n",
      "    70                                                   # Load models if specified (only the params, and only if compatible)\n",
      "    71         1        210.0    210.0      0.0          load_models_if_specified(self, verbose=self.verbose)\n",
      "    72                                           \n",
      "    73         1          4.0      4.0      0.0          fidelities_history, losses_history = [], []\n",
      "    74         1         68.0     68.0      0.0          starttime = datetime.now()\n",
      "    75         1          6.0      6.0      0.0          num_epochs: int = 0\n",
      "    76                                           \n",
      "    77                                                   ###########################################################\n",
      "    78                                                   # Main Training Block\n",
      "    79                                                   ###########################################################\n",
      "    80         1          6.0      6.0      0.0          while True:\n",
      "    81                                                       # while (f < 0.95):\n",
      "    82         1          3.0      3.0      0.0              fidelities = []\n",
      "    83         1          3.0      3.0      0.0              losses = []\n",
      "    84         1          4.0      4.0      0.0              num_epochs += 1\n",
      "    85        21        140.0      6.7      0.0              for epoch_iter in range(self.config.iterations_epoch):\n",
      "    86                                                           ###########################################################\n",
      "    87                                                           # Gen and Dis gradient descent\n",
      "    88                                                           ###########################################################\n",
      "    89        40        384.0      9.6      0.0                  for _ in range(self.config.steps_gen):\n",
      "    90        20   12879584.0 643979.2     14.9                      self.gen.update_gen(self.dis, self.final_target_state)\n",
      "    91                                           \n",
      "    92                                                           # Remove ancilla if needed, with ancilla mode, before discriminator:\n",
      "    93        20        604.0     30.2      0.0                  final_gen_state = get_final_gen_state_for_discriminator(self.gen.total_gen_state)\n",
      "    94                                           \n",
      "    95        40        340.0      8.5      0.0                  for _ in range(self.config.steps_dis):\n",
      "    96        20   62519099.0    3e+06     72.1                      self.dis.update_dis(self.final_target_state, final_gen_state)\n",
      "    97                                           \n",
      "    98                                                           ###########################################################\n",
      "    99                                                           # Every X iterations: compute and save fidelity & loss\n",
      "   100                                                           ###########################################################\n",
      "   101        20        383.0     19.1      0.0                  if epoch_iter % self.config.save_fid_and_loss_every_x_iter == 0:\n",
      "   102        20   11177903.0 558895.2     12.9                      fid, loss = compute_fidelity_and_cost(self.dis, self.final_target_state, final_gen_state)\n",
      "   103        20        258.0     12.9      0.0                      fidelities.append(fid), losses.append(loss)\n",
      "   104                                           \n",
      "   105                                                           ############################################################\n",
      "   106                                                           # Every X iterations: Print and log fidelity and loss\n",
      "   107                                                           ############################################################\n",
      "   108        20        397.0     19.9      0.0                  if epoch_iter % self.config.log_every_x_iter == 0:\n",
      "   109         4        354.0     88.5      0.0                      info = \"\\nepoch:{:4d} | iters:{:4d} | fidelity:{:8f} | loss:{:8f}\".format(\n",
      "   110         2        544.0    272.0      0.0                          num_epochs, epoch_iter + 1, round(fid, 6), round(loss, 6)\n",
      "   111                                                               )\n",
      "   112         2         22.0     11.0      0.0                      if self.verbose:\n",
      "   113                                                                   print_and_log(info, self.config.log_path)\n",
      "   114                                           \n",
      "   115                                                       ###########################################################\n",
      "   116                                                       # End of epoch, store data and plot\n",
      "   117                                                       ###########################################################\n",
      "   118         1        221.0    221.0      0.0              fidelities_history = np.append(fidelities_history, fidelities)\n",
      "   119         1        109.0    109.0      0.0              losses_history = np.append(losses_history, losses)\n",
      "   120                                                       #plt_fidelity_vs_iter(fidelities_history, losses_history, CFG, num_epochs)\n",
      "   121                                           \n",
      "   122                                                       #############################################################\n",
      "   123                                                       # Stopping conditions\n",
      "   124                                                       #############################################################\n",
      "   125         1          4.0      4.0      0.0              if num_epochs >= self.config.epochs:\n",
      "   126         1          6.0      6.0      0.0                  if self.verbose:\n",
      "   127                                                               print_and_log(\"\\n==================================================\\n\", self.config.log_path)\n",
      "   128                                                               print_and_log(f\"\\nThe number of epochs exceeds {self.config.epochs}.\", self.config.log_path)\n",
      "   129         1          8.0      8.0      0.0                  break\n",
      "   130                                           \n",
      "   131                                                       if fidelities[-1] > self.config.max_fidelity:  # TODO: Maybe change this cond, to use max(fidelities)?\n",
      "   132                                                           if self.verbose:\n",
      "   133                                                               print_and_log(\"\\n==================================================\\n\", self.config.log_path)\n",
      "   134                                                               print_and_log(\n",
      "   135                                                                   f\"\\nThe fidelity {fidelities[-1]} exceeds the maximum {self.config.max_fidelity}.\",\n",
      "   136                                                                   self.config.log_path,\n",
      "   137                                                               )\n",
      "   138                                                           break\n",
      "   139                                           \n",
      "   140                                                   ###########################################################\n",
      "   141                                                   # End training, save all data into files\n",
      "   142                                                   ###########################################################\n",
      "   143                                                   # Save data of fidelity and loss\n",
      "   144         1      15029.0  15029.0      0.0          save_fidelity_loss(fidelities_history, losses_history, self.config.fid_loss_path)\n",
      "   145                                           \n",
      "   146                                                   # Save data of the generator and the discriminator\n",
      "   147         1      24147.0  24147.0      0.0          save_model(self.gen, self.config.model_gen_path)\n",
      "   148         1       7179.0   7179.0      0.0          save_model(self.dis, self.config.model_dis_path)\n",
      "   149                                           \n",
      "   150                                                   # Output the parameters of the generator\n",
      "   151         1      28988.0  28988.0      0.0          save_gen_final_params(self.gen, self.config.gen_final_params_path)\n",
      "   152                                           \n",
      "   153         1         76.0     76.0      0.0          endtime = datetime.now()\n",
      "   154         1          8.0      8.0      0.0          if self.verbose:\n",
      "   155                                                       print_and_log(f\"\\nRun took: {endtime - starttime} time.\", self.config.log_path)\n",
      "   156                                           \n",
      "   157         1          6.0      6.0      0.0          return losses_history, fidelities_history\n",
      "\n",
      "Total time: 0.123935 s\n",
      "File: c:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\tools\\qobjects\\qcircuit.py\n",
      "Function: get_grad_mat_rep at line 47\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    47                                               def get_grad_mat_rep(self, index, signal=\"none\", type=\"matrix_multiplication\") -> np.ndarray:\n",
      "    48                                                   \"\"\"Matrix multipliction: explicit way to calculate the gradient using matrix multiplication.\n",
      "    49                                           \n",
      "    50                                                   Shift_phase: generate two quantum circuit to calculate the gradient evaluating analytic gradients on quantum hardware:\n",
      "    51                                                   https://arxiv.org/pdf/1811.11184.pdf\n",
      "    52                                                   \"\"\"\n",
      "    53       100        667.0      6.7      0.1          if type == \"shift_phase\":\n",
      "    54                                                       matrix = Identity(self.size)\n",
      "    55                                                       for j, gate_j in enumerate(self.gates):\n",
      "    56                                                           if index == j:\n",
      "    57                                                               g = gate_j.matrix_representation_shift_phase(self.size, True, signal)\n",
      "    58                                                           else:\n",
      "    59                                                               g = gate_j.matrix_representation_shift_phase(self.size, False, signal)\n",
      "    60                                                           matrix = np.matmul(g, matrix)\n",
      "    61                                                       return np.asarray(matrix)\n",
      "    62                                           \n",
      "    63       100        450.0      4.5      0.0          if type == \"matrix_multiplication\":\n",
      "    64       100     142400.0   1424.0     11.5              matrix = Identity(self.size)\n",
      "    65       600       4746.0      7.9      0.4              for j, gate_j in enumerate(self.gates):\n",
      "    66       500       2052.0      4.1      0.2                  if index == j:\n",
      "    67       100     227989.0   2279.9     18.4                      g = gate_j.matrix_representation(self.size, True)\n",
      "    68                                                           else:\n",
      "    69       400     830187.0   2075.5     67.0                      g = gate_j.matrix_representation(self.size, False)\n",
      "    70       500      30123.0     60.2      2.4                  matrix = np.matmul(g, matrix)\n",
      "    71       100        741.0      7.4      0.1              return np.asarray(matrix)\n",
      "    72                                           \n",
      "    73                                                   return None\n",
      "\n",
      "Total time: 8.67029 s\n",
      "File: c:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\tools\\training_init.py\n",
      "Function: run_single_training at line 35\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    35                                           def run_single_training(config=CFG, verbose=True, seed=None):\n",
      "    36                                               \"\"\"\n",
      "    37                                               Runs a single training instance.\n",
      "    38                                               \"\"\"\n",
      "    39         1         10.0     10.0      0.0      if verbose:\n",
      "    40                                                   print_and_log(\"Running in SINGLE RUN mode.\\n\", config.log_path)\n",
      "    41                                           \n",
      "    42         1          9.0      9.0      0.0      try:\n",
      "    43                                                   ##############################################################\n",
      "    44                                                   # Run single training instance with specified configuration\n",
      "    45                                                   ##############################################################\n",
      "    46         1      43576.0  43576.0      0.1          training_instance = Training(config=config, verbose=verbose, seed=seed)\n",
      "    47         1   86659304.0    9e+07     99.9          res = training_instance.run()\n",
      "    48         1          8.0      8.0      0.0          success_msg = \"\\nDefault configuration run COMPLETED SUCCESSFULLY.\\n\"\n",
      "    49         1          7.0      7.0      0.0          if verbose:\n",
      "    50                                                       print_and_log(success_msg, config.log_path)  # Log to file\n",
      "    51         1          4.0      4.0      0.0          return res\n",
      "    52                                           \n",
      "    53                                               except Exception as e:  # noqa: BLE001\n",
      "    54                                                   ##############################################################\n",
      "    55                                                   # Handle exceptions during the training run\n",
      "    56                                                   ##############################################################\n",
      "    57                                                   tb_str = traceback.format_exc()\n",
      "    58                                                   error_msg = (\n",
      "    59                                                       f\"\\n{'-' * 60}\\n\"\n",
      "    60                                                       f\"FAILED: Default configuration run!\\n\"\n",
      "    61                                                       f\"Error Type: {type(e).__name__}\\n\"\n",
      "    62                                                       f\"Error Message: {e!s}\\n\"\n",
      "    63                                                       f\"Traceback:\\n{tb_str}\"\n",
      "    64                                                       f\"{'=' * 60}\\n\"\n",
      "    65                                                   )\n",
      "    66                                                   if verbose:\n",
      "    67                                                       print_and_log(error_msg, config.log_path)  # Log to file"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler\n",
    "%lprun -f tools.training_init.run_single_training -f Training.run -f Generator.update_gen -f Generator._grad_theta -f Generator.get_total_gen_grad -f QuantumCircuit.get_grad_mat_rep -f Discriminator.update_dis -f Discriminator._compute_grad -f Discriminator._grad_alpha -f Discriminator._grad_beta -f Discriminator._grad_psi_or_phi -f Discriminator run_single_training(config=config, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b86e87b",
   "metadata": {},
   "source": [
    "### 1.2. Complete run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d18c951b",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = copy.deepcopy(CFG)\n",
    "\n",
    "config.run_multiple_experiments = False\n",
    "config.extra_ancilla = False\n",
    "config.epochs = 1\n",
    "config.iterations_epoch = 100\n",
    "config.gen_layers = 1\n",
    "config.gen_ansatz = \"XX_YY_ZZ_Z\"\n",
    "config.target_hamiltonian = \"custom_h\"\n",
    "config.custom_hamiltonian_terms = [\"ZZZ\", \"ZZ\", \"XX\", \"XZ\"]\n",
    "config.label_suffix = \"c1_2q_1l_noanc_XXYYZZZ_CustomH_ZZZ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9db0bb4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in SINGLE RUN mode.\n",
      "\n",
      "\n",
      "================================================== \n",
      "run_timestamp: 2025-07-24__07-24-16,\n",
      "----------------------------------------------\n",
      "load_timestamp: None,\n",
      "type_of_warm_start: none,\n",
      "warm_start_strength: 0.1,\n",
      "----------------------------------------------\n",
      "system_size: 3,\n",
      "extra_ancilla: False,\n",
      "ancilla_mode: pass,\n",
      "ancilla_project_norm: re-norm,\n",
      "ancilla_topology: bridge,\n",
      "ancilla_connect_to: None,\n",
      "do_ancilla_1q_gates: False,\n",
      "start_ancilla_gates_randomly: False,\n",
      "----------------------------------------------\n",
      "gen_layers: 1,\n",
      "gen_ansatz: XX_YY_ZZ_Z,\n",
      "----------------------------------------------\n",
      "target_hamiltonian: custom_h,\n",
      "custom_hamiltonian_terms: ['ZZZ', 'ZZ', 'XX', 'XZ'],\n",
      "custom_hamiltonian_strengths: [1.0, 0.1],\n",
      "----------------------------------------------\n",
      "epochs: 1,\n",
      "iterations_epoch: 100,\n",
      "log_every_x_iter: 10,\n",
      "save_fid_and_loss_every_x_iter: 1,\n",
      "max_fidelity: 0.99,\n",
      "steps_gen: 1,\n",
      "steps_dis: 1,\n",
      "----------------------------------------------\n",
      "l_rate: 0.01,\n",
      "momentum_coeff: 0.9,\n",
      "================================================== \n",
      "\n",
      "\n",
      "Starting training from scratch (no timestamp specified).\n",
      "\n",
      "==================================================\n",
      "\n",
      "\n",
      "epoch:   1 | iters:   1 | fidelity:0.001549 | loss:-3.563304\n",
      "\n",
      "epoch:   1 | iters:  11 | fidelity:0.001489 | loss:-3.430281\n",
      "\n",
      "epoch:   1 | iters:  21 | fidelity:0.001435 | loss:-3.170295\n",
      "\n",
      "epoch:   1 | iters:  31 | fidelity:0.001517 | loss:-2.922036\n",
      "\n",
      "epoch:   1 | iters:  41 | fidelity:0.001949 | loss:-2.657593\n",
      "\n",
      "epoch:   1 | iters:  51 | fidelity:0.003312 | loss:-2.451703\n",
      "\n",
      "epoch:   1 | iters:  61 | fidelity:0.003604 | loss:-1.052613\n",
      "\n",
      "epoch:   1 | iters:  71 | fidelity:0.002641 | loss:0.009991\n",
      "\n",
      "epoch:   1 | iters:  81 | fidelity:0.002197 | loss:0.124770\n",
      "\n",
      "epoch:   1 | iters:  91 | fidelity:0.002039 | loss:0.138977\n",
      "\n",
      "==================================================\n",
      "\n",
      "\n",
      "The number of epochs exceeds 1.\n",
      "\n",
      "Run took: 0:00:06.953671 time.\n",
      "\n",
      "Default configuration run COMPLETED SUCCESSFULLY.\n",
      "\n",
      "Runtime = 6.97392369993031s\n",
      "(array([-3.56330366, -3.55744838, -3.54920551, -3.53892057, -3.52690897,\n",
      "       -3.51344449, -3.4987515 , -3.48300058, -3.46630699, -3.44873125,\n",
      "       -3.43028099, -3.41091371, -3.39054005, -3.36902758, -3.34620561,\n",
      "       -3.32187198, -3.29580355, -3.26777322, -3.2375778 , -3.20508319,\n",
      "       -3.17029529, -3.13346634, -3.09524277, -3.05684404, -3.02021641,\n",
      "       -2.98801044, -2.96309363, -2.94726451, -2.93927314, -2.9335406 ,\n",
      "       -2.92203636, -2.89953859, -2.8674959 , -2.83206378, -2.79899359,\n",
      "       -2.77070887, -2.74666478, -2.72496924, -2.70367825, -2.68142402,\n",
      "       -2.6575934 , -2.63230156, -2.60628764, -2.58075631, -2.55713178,\n",
      "       -2.53667607, -2.51996167, -2.50628774, -2.49325928, -2.47679952,\n",
      "       -2.45170318, -2.41249298, -2.35412048, -2.27224383, -2.16327042,\n",
      "       -2.02464569, -1.85584641, -1.66034698, -1.44835366, -1.23845422,\n",
      "       -1.05261336, -0.89802822, -0.74964127, -0.57668864, -0.39318062,\n",
      "       -0.23947678, -0.13222949, -0.06257687, -0.01840687,  0.0050804 ,\n",
      "        0.00999124,  0.00561044,  0.0085106 ,  0.02792855,  0.05721127,\n",
      "        0.08495684,  0.10651454,  0.12234772,  0.13197499,  0.132871  ,\n",
      "        0.12476997,  0.11331577,  0.1064766 ,  0.10671601,  0.1099471 ,\n",
      "        0.11214312,  0.11352747,  0.11662966,  0.12277307,  0.13090483,\n",
      "        0.138977  ,  0.14592894,  0.15214643,  0.15811329,  0.16324722,\n",
      "        0.16650375,  0.16774049,  0.16803099,  0.16874712,  0.17052781]), array([0.00154866, 0.00154613, 0.00154252, 0.00153795, 0.00153253,\n",
      "       0.00152637, 0.00151959, 0.00151232, 0.0015047 , 0.00149684,\n",
      "       0.0014889 , 0.00148101, 0.00147331, 0.00146594, 0.00145904,\n",
      "       0.00145274, 0.00144717, 0.00144247, 0.00143875, 0.00143613,\n",
      "       0.00143474, 0.0014347 , 0.00143612, 0.00143915, 0.00144391,\n",
      "       0.00145054, 0.00145918, 0.00147   , 0.00148316, 0.00149883,\n",
      "       0.00151725, 0.00153865, 0.00156337, 0.00159181, 0.00162448,\n",
      "       0.00166197, 0.00170497, 0.00175427, 0.00181075, 0.00187541,\n",
      "       0.00194931, 0.00203359, 0.00212938, 0.0022377 , 0.00235933,\n",
      "       0.00249455, 0.00264287, 0.00280267, 0.00297092, 0.00314291,\n",
      "       0.00331234, 0.00347161, 0.00361252, 0.00372727, 0.00380952,\n",
      "       0.00385541, 0.00386408, 0.00383779, 0.00378133, 0.0037012 ,\n",
      "       0.00360448, 0.00349792, 0.00338719, 0.00327652, 0.00316872,\n",
      "       0.00306552, 0.00296795, 0.0028766 , 0.00279174, 0.0027134 ,\n",
      "       0.00264144, 0.00257557, 0.00251544, 0.00246065, 0.00241084,\n",
      "       0.00236564, 0.00232471, 0.00228772, 0.00225434, 0.00222422,\n",
      "       0.00219707, 0.00217259, 0.00215053, 0.00213065, 0.00211277,\n",
      "       0.00209673, 0.00208237, 0.00206955, 0.00205811, 0.0020479 ,\n",
      "       0.00203879, 0.00203063, 0.00202331, 0.00201672, 0.00201078,\n",
      "       0.00200541, 0.00200056, 0.00199619, 0.00199225, 0.0019887 ]))\n"
     ]
    }
   ],
   "source": [
    "t0 = tpc()\n",
    "res = run_single_training(config=config, verbose=True, seed=42)\n",
    "t1 = tpc()\n",
    "print(f'Runtime = {t1-t0}s')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8ee5528b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.21 s ± 618 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit run_single_training(config=config, verbose=False, seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4f631878",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in SINGLE RUN mode.\n",
      "\n",
      "\n",
      "================================================== \n",
      "run_timestamp: 2025-07-24__07-24-16,\n",
      "----------------------------------------------\n",
      "load_timestamp: None,\n",
      "type_of_warm_start: none,\n",
      "warm_start_strength: 0.1,\n",
      "----------------------------------------------\n",
      "system_size: 3,\n",
      "extra_ancilla: False,\n",
      "ancilla_mode: pass,\n",
      "ancilla_project_norm: re-norm,\n",
      "ancilla_topology: bridge,\n",
      "ancilla_connect_to: None,\n",
      "do_ancilla_1q_gates: False,\n",
      "start_ancilla_gates_randomly: False,\n",
      "----------------------------------------------\n",
      "gen_layers: 3,\n",
      "gen_ansatz: ZZ_X_Z,\n",
      "----------------------------------------------\n",
      "target_hamiltonian: custom_h,\n",
      "custom_hamiltonian_terms: ['XZ', 'X'],\n",
      "custom_hamiltonian_strengths: [1.0, 0.1],\n",
      "----------------------------------------------\n",
      "epochs: 10,\n",
      "iterations_epoch: 300,\n",
      "log_every_x_iter: 10,\n",
      "save_fid_and_loss_every_x_iter: 1,\n",
      "max_fidelity: 0.99,\n",
      "steps_gen: 1,\n",
      "steps_dis: 1,\n",
      "----------------------------------------------\n",
      "l_rate: 0.01,\n",
      "momentum_coeff: 0.9,\n",
      "================================================== \n",
      "\n",
      "\n",
      "Starting training from scratch (no timestamp specified).\n",
      "\n",
      "==================================================\n",
      "\n",
      "\n",
      "epoch:   1 | iters:   1 | fidelity:0.005456 | loss:-3.744550\n",
      "\n",
      "epoch:   1 | iters:  11 | fidelity:0.006036 | loss:-3.428219\n",
      "\n",
      "epoch:   1 | iters:  21 | fidelity:0.007139 | loss:-3.085855\n",
      "\n",
      "epoch:   1 | iters:  31 | fidelity:0.008729 | loss:-2.775744\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m t0 = tpc()\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m res = \u001b[43mrun_single_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCFG\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m42\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      3\u001b[39m t1 = tpc()\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[33mRuntime = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mt1-t0\u001b[38;5;132;01m}\u001b[39;00m\u001b[33ms\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\tools\\training_init.py:47\u001b[39m, in \u001b[36mrun_single_training\u001b[39m\u001b[34m(config, verbose, seed)\u001b[39m\n\u001b[32m     42\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     43\u001b[39m     \u001b[38;5;66;03m##############################################################\u001b[39;00m\n\u001b[32m     44\u001b[39m     \u001b[38;5;66;03m# Run single training instance with specified configuration\u001b[39;00m\n\u001b[32m     45\u001b[39m     \u001b[38;5;66;03m##############################################################\u001b[39;00m\n\u001b[32m     46\u001b[39m     training_instance = Training(config=config, verbose=verbose, seed=seed)\n\u001b[32m---> \u001b[39m\u001b[32m47\u001b[39m     res = \u001b[43mtraining_instance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     48\u001b[39m     success_msg = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mDefault configuration run COMPLETED SUCCESSFULLY.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     49\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m verbose:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\qgan\\training.py:89\u001b[39m, in \u001b[36mTraining.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     84\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m epoch_iter \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.config.iterations_epoch):\n\u001b[32m     85\u001b[39m     \u001b[38;5;66;03m###########################################################\u001b[39;00m\n\u001b[32m     86\u001b[39m     \u001b[38;5;66;03m# Gen and Dis gradient descent\u001b[39;00m\n\u001b[32m     87\u001b[39m     \u001b[38;5;66;03m###########################################################\u001b[39;00m\n\u001b[32m     88\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.config.steps_gen):\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mupdate_gen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfinal_target_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     91\u001b[39m     \u001b[38;5;66;03m# Remove ancilla if needed, with ancilla mode, before discriminator:\u001b[39;00m\n\u001b[32m     92\u001b[39m     final_gen_state = get_final_gen_state_for_discriminator(\u001b[38;5;28mself\u001b[39m.gen.total_gen_state)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\qgan\\generator.py:91\u001b[39m, in \u001b[36mGenerator.update_gen\u001b[39m\u001b[34m(self, dis, final_target_state)\u001b[39m\n\u001b[32m     82\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Update the generator parameters (angles) using the optimizer.\u001b[39;00m\n\u001b[32m     83\u001b[39m \n\u001b[32m     84\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m     85\u001b[39m \u001b[33;03m    dis (Discriminator): The discriminator to compute gradients.\u001b[39;00m\n\u001b[32m     86\u001b[39m \u001b[33;03m    final_target_state (np.ndarray): The target state vector.\u001b[39;00m\n\u001b[32m     87\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     88\u001b[39m \u001b[38;5;66;03m###############################################################\u001b[39;00m\n\u001b[32m     89\u001b[39m \u001b[38;5;66;03m# Compute the gradient\u001b[39;00m\n\u001b[32m     90\u001b[39m \u001b[38;5;66;03m###############################################################\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m grad: np.ndarray = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_grad_theta\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_target_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mtotal_gen_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[38;5;66;03m# Get the new thetas from the gradient\u001b[39;00m\n\u001b[32m     94\u001b[39m theta = np.asarray([gate.angle \u001b[38;5;28;01mfor\u001b[39;00m gate \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.qc.gates])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\qgan\\generator.py:149\u001b[39m, in \u001b[36mGenerator._grad_theta\u001b[39m\u001b[34m(self, dis, final_target_state, total_gen_state)\u001b[39m\n\u001b[32m    146\u001b[39m grad_g_psi.append(\u001b[32m0\u001b[39m)\n\u001b[32m    148\u001b[39m \u001b[38;5;66;03m# For phi term\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m149\u001b[39m total_gen_grad = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mget_total_gen_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    150\u001b[39m final_gen_grad = get_final_gen_state_for_discriminator(total_gen_grad)\n\u001b[32m    151\u001b[39m final_gen_grad = np.asarray(final_gen_grad)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\qgan\\generator.py:78\u001b[39m, in \u001b[36mGenerator.get_total_gen_grad\u001b[39m\u001b[34m(self, index)\u001b[39m\n\u001b[32m     69\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_total_gen_grad\u001b[39m(\u001b[38;5;28mself\u001b[39m, index) -> np.ndarray:\n\u001b[32m     70\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Get the total generator gradient for a specific gate index.\u001b[39;00m\n\u001b[32m     71\u001b[39m \n\u001b[32m     72\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     76\u001b[39m \u001b[33;03m        np.ndarray: The total generator gradient vector for the specified gate.\u001b[39;00m\n\u001b[32m     77\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     Untouched_x_G_grad_i = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mkron\u001b[49m\u001b[43m(\u001b[49m\u001b[43mIdentity\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m.\u001b[49m\u001b[43msystem_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mqc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_grad_mat_rep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     79\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m np.matmul(Untouched_x_G_grad_i, \u001b[38;5;28mself\u001b[39m.total_input_state)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\f52ga\\miniforge3\\envs\\qgan\\Lib\\site-packages\\numpy\\lib\\_shape_base_impl.py:1199\u001b[39m, in \u001b[36mkron\u001b[39m\u001b[34m(a, b)\u001b[39m\n\u001b[32m   1197\u001b[39m b_arr = expand_dims(b_arr, axis=\u001b[38;5;28mtuple\u001b[39m(\u001b[38;5;28mrange\u001b[39m(\u001b[32m0\u001b[39m, nd * \u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m)))\n\u001b[32m   1198\u001b[39m \u001b[38;5;66;03m# In case of `mat`, convert result to `array`\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1199\u001b[39m result = \u001b[43m_nx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmultiply\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma_arr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mb_arr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msubok\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mis_any_mat\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1201\u001b[39m \u001b[38;5;66;03m# Reshape back\u001b[39;00m\n\u001b[32m   1202\u001b[39m result = result.reshape(_nx.multiply(as_, bs))\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "t0 = tpc()\n",
    "res = run_single_training(config=CFG, verbose=True, seed=42)\n",
    "t1 = tpc()\n",
    "print(f'Runtime = {t1-t0}s')\n",
    "print(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81a2d34f",
   "metadata": {},
   "source": [
    "### 1.3. Test memory\n",
    "\n",
    "Let us test the memory limits of this technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "06ef1918",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = copy.deepcopy(CFG)\n",
    "\n",
    "config.run_multiple_experiments = False\n",
    "config.system_size = 8\n",
    "config.extra_ancilla = False\n",
    "config.epochs = 1\n",
    "config.iterations_epoch = 3\n",
    "config.gen_layers = 1\n",
    "config.gen_ansatz = \"XX_YY_ZZ_Z\"\n",
    "config.target_hamiltonian = \"custom_h\"\n",
    "config.custom_hamiltonian_terms = [\"ZZZ\", \"ZZ\", \"XX\", \"XZ\"]\n",
    "config.label_suffix = \"c1_2q_1l_noanc_XXYYZZZ_CustomH_ZZZ\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9c328f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in SINGLE RUN mode.\n",
      "\n",
      "\n",
      "------------------------------------------------------------\n",
      "FAILED: Default configuration run!\n",
      "Error Type: MemoryError\n",
      "Error Message: Unable to allocate 64.0 GiB for an array with shape (256, 256, 256, 256) and data type complex128\n",
      "Traceback:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\tools\\training_init.py\", line 46, in run_single_training\n",
      "    training_instance = Training(config=config, verbose=verbose, seed=seed)\n",
      "  File \"c:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\qgan\\training.py\", line 51, in __init__\n",
      "    self.final_target_state: np.matrix = get_final_target_state(initial_state_final, self.config)\n",
      "                                         ~~~~~~~~~~~~~~~~~~~~~~^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\qgan\\target.py\", line 62, in get_final_target_state\n",
      "    target_op = np.kron(Identity(config.system_size), target_unitary)\n",
      "  File \"c:\\Users\\f52ga\\miniforge3\\envs\\qgan\\Lib\\site-packages\\numpy\\lib\\_shape_base_impl.py\", line 1199, in kron\n",
      "    result = _nx.multiply(a_arr, b_arr, subok=(not is_any_mat))\n",
      "numpy._core._exceptions._ArrayMemoryError: Unable to allocate 64.0 GiB for an array with shape (256, 256, 256, 256) and data type complex128\n",
      "============================================================\n",
      "\n",
      "Runtime = 0.30793590005487204s\n"
     ]
    }
   ],
   "source": [
    "t0 = tpc()\n",
    "res = run_single_training(config=config, verbose=True, seed=42)\n",
    "t1 = tpc()\n",
    "print(f'Runtime = {t1-t0}s')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qgan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
