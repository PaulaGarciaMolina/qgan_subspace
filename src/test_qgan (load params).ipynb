{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "52a74478",
   "metadata": {},
   "source": [
    "# Load parameters\n",
    "\n",
    "Add possibility of loading parameters of pretrained circuits to new ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d261955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU device selected.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\f52ga\\miniforge3\\envs\\qgan\\Lib\\site-packages\\pennylane\\__init__.py:196: RuntimeWarning: PennyLane is not yet compatible with JAX versions > 0.6.2. You have version 0.7.0 installed. Please downgrade JAX to 0.6.2 to avoid runtime errors using python -m pip install jax~=0.6.0 jaxlib~=0.6.0\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from qgan.training import Training\n",
    "from config import CFG\n",
    "from tools.data.data_managers import save_model\n",
    "import os \n",
    "import pickle\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3f756515",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = copy.deepcopy(CFG)\n",
    "config.epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8e02d7",
   "metadata": {},
   "source": [
    "## 1. Generator "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "949610f7",
   "metadata": {},
   "source": [
    "### 1.1. Same configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9649af",
   "metadata": {},
   "source": [
    "- Run training instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86e827d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================== \n",
      "run_timestamp: 2025-11-12__16-15-55,\n",
      "----------------------------------------------\n",
      "load_timestamp: None,\n",
      "type_of_warm_start: none,\n",
      "warm_start_strength: 0.1,\n",
      "----------------------------------------------\n",
      "system_size: 3,\n",
      "extra_ancilla: False,\n",
      "ancilla_mode: pass,\n",
      "ancilla_project_norm: re-norm,\n",
      "ancilla_topology: bridge,\n",
      "ancilla_connect_to: None,\n",
      "do_ancilla_1q_gates: True,\n",
      "start_ancilla_gates_randomly: True,\n",
      "----------------------------------------------\n",
      "gen_layers: 3,\n",
      "gen_ansatz: ZZ_X_Z,\n",
      "----------------------------------------------\n",
      "target_hamiltonian: custom_h,\n",
      "custom_hamiltonian_terms: ['ZZZ'],\n",
      "custom_hamiltonian_strengths: [1.0],\n",
      "----------------------------------------------\n",
      "epochs: 2,\n",
      "iterations_epoch: 300,\n",
      "log_every_x_iter: 10,\n",
      "save_fid_and_loss_every_x_iter: 1,\n",
      "max_fidelity: 0.99,\n",
      "steps_gen: 1,\n",
      "steps_dis: 1,\n",
      "----------------------------------------------\n",
      "l_rate: 0.01,\n",
      "momentum_coeff: 0.9,\n",
      "================================================== \n",
      "\n",
      "\n",
      "Epoch:    1 | Iter:    1 | Fidelity: 0.004656 | Loss: -3.645709\n",
      "\n",
      "Epoch:    1 | Iter:   11 | Fidelity: 0.004533 | Loss: -3.297681\n",
      "\n",
      "Epoch:    1 | Iter:   21 | Fidelity: 0.004352 | Loss: -3.091377\n",
      "\n",
      "Epoch:    1 | Iter:   31 | Fidelity: 0.004162 | Loss: -3.010880\n",
      "\n",
      "Epoch:    1 | Iter:   41 | Fidelity: 0.003936 | Loss: -2.942088\n",
      "\n",
      "Epoch:    1 | Iter:   51 | Fidelity: 0.003619 | Loss: -2.831710\n",
      "\n",
      "Epoch:    1 | Iter:   61 | Fidelity: 0.003103 | Loss: -2.592340\n",
      "\n",
      "Epoch:    1 | Iter:   71 | Fidelity: 0.002249 | Loss: -2.437463\n",
      "\n",
      "Epoch:    1 | Iter:   81 | Fidelity: 0.001128 | Loss: -2.458521\n",
      "\n",
      "Epoch:    1 | Iter:   91 | Fidelity: 0.000232 | Loss: -2.455015\n",
      "\n",
      "Epoch:    1 | Iter:  101 | Fidelity: 0.000033 | Loss: -2.217770\n",
      "\n",
      "Epoch:    1 | Iter:  111 | Fidelity: 0.000411 | Loss: -1.317811\n",
      "\n",
      "Epoch:    1 | Iter:  121 | Fidelity: 0.000783 | Loss: -0.342201\n",
      "\n",
      "Epoch:    1 | Iter:  131 | Fidelity: 0.000983 | Loss: -0.118888\n",
      "\n",
      "Epoch:    1 | Iter:  141 | Fidelity: 0.001114 | Loss: -0.080960\n",
      "\n",
      "Epoch:    1 | Iter:  151 | Fidelity: 0.001213 | Loss: -0.076997\n",
      "\n",
      "Epoch:    1 | Iter:  161 | Fidelity: 0.001299 | Loss: -0.062437\n",
      "\n",
      "Epoch:    1 | Iter:  171 | Fidelity: 0.001385 | Loss: -0.058552\n",
      "\n",
      "Epoch:    1 | Iter:  181 | Fidelity: 0.001472 | Loss: -0.058367\n",
      "\n",
      "Epoch:    1 | Iter:  191 | Fidelity: 0.001561 | Loss: -0.057553\n",
      "\n",
      "Epoch:    1 | Iter:  201 | Fidelity: 0.001653 | Loss: -0.057196\n",
      "\n",
      "Epoch:    1 | Iter:  211 | Fidelity: 0.001748 | Loss: -0.057064\n",
      "\n",
      "Epoch:    1 | Iter:  221 | Fidelity: 0.001847 | Loss: -0.056936\n",
      "\n",
      "Epoch:    1 | Iter:  231 | Fidelity: 0.001950 | Loss: -0.056831\n",
      "\n",
      "Epoch:    1 | Iter:  241 | Fidelity: 0.002058 | Loss: -0.056750\n",
      "\n",
      "Epoch:    1 | Iter:  251 | Fidelity: 0.002170 | Loss: -0.056683\n",
      "\n",
      "Epoch:    1 | Iter:  261 | Fidelity: 0.002287 | Loss: -0.056624\n",
      "\n",
      "Epoch:    1 | Iter:  271 | Fidelity: 0.002410 | Loss: -0.056581\n",
      "\n",
      "Epoch:    1 | Iter:  281 | Fidelity: 0.002538 | Loss: -0.056536\n",
      "\n",
      "Epoch:    1 | Iter:  291 | Fidelity: 0.002673 | Loss: -0.056512\n",
      "\n",
      "Epoch:    2 | Iter:    1 | Fidelity: 0.002813 | Loss: -0.056489\n",
      "\n",
      "Epoch:    2 | Iter:   11 | Fidelity: 0.002961 | Loss: -0.056471\n",
      "\n",
      "Epoch:    2 | Iter:   21 | Fidelity: 0.003116 | Loss: -0.056458\n",
      "\n",
      "Epoch:    2 | Iter:   31 | Fidelity: 0.003279 | Loss: -0.056458\n",
      "\n",
      "Epoch:    2 | Iter:   41 | Fidelity: 0.003450 | Loss: -0.056455\n",
      "\n",
      "Epoch:    2 | Iter:   51 | Fidelity: 0.003631 | Loss: -0.056458\n",
      "\n",
      "Epoch:    2 | Iter:   61 | Fidelity: 0.003821 | Loss: -0.056467\n",
      "\n",
      "Epoch:    2 | Iter:   71 | Fidelity: 0.004021 | Loss: -0.056482\n",
      "\n",
      "Epoch:    2 | Iter:   81 | Fidelity: 0.004233 | Loss: -0.056504\n",
      "\n",
      "Epoch:    2 | Iter:   91 | Fidelity: 0.004457 | Loss: -0.056527\n",
      "\n",
      "Epoch:    2 | Iter:  101 | Fidelity: 0.004693 | Loss: -0.056562\n",
      "\n",
      "Epoch:    2 | Iter:  111 | Fidelity: 0.004944 | Loss: -0.056594\n",
      "\n",
      "Epoch:    2 | Iter:  121 | Fidelity: 0.005210 | Loss: -0.056640\n",
      "\n",
      "Epoch:    2 | Iter:  131 | Fidelity: 0.005492 | Loss: -0.056685\n",
      "\n",
      "Epoch:    2 | Iter:  141 | Fidelity: 0.005792 | Loss: -0.056743\n",
      "\n",
      "Epoch:    2 | Iter:  151 | Fidelity: 0.006111 | Loss: -0.056805\n",
      "\n",
      "Epoch:    2 | Iter:  161 | Fidelity: 0.006451 | Loss: -0.056871\n",
      "\n",
      "Epoch:    2 | Iter:  171 | Fidelity: 0.006814 | Loss: -0.056951\n",
      "\n",
      "Epoch:    2 | Iter:  181 | Fidelity: 0.007201 | Loss: -0.057034\n",
      "\n",
      "Epoch:    2 | Iter:  191 | Fidelity: 0.007616 | Loss: -0.057131\n",
      "\n",
      "Epoch:    2 | Iter:  201 | Fidelity: 0.008061 | Loss: -0.057238\n",
      "\n",
      "Epoch:    2 | Iter:  211 | Fidelity: 0.008538 | Loss: -0.057356\n",
      "\n",
      "Epoch:    2 | Iter:  221 | Fidelity: 0.009051 | Loss: -0.057484\n",
      "\n",
      "Epoch:    2 | Iter:  231 | Fidelity: 0.009603 | Loss: -0.057632\n",
      "\n",
      "Epoch:    2 | Iter:  241 | Fidelity: 0.010199 | Loss: -0.057791\n",
      "\n",
      "Epoch:    2 | Iter:  251 | Fidelity: 0.010844 | Loss: -0.057971\n",
      "\n",
      "Epoch:    2 | Iter:  261 | Fidelity: 0.011541 | Loss: -0.058174\n",
      "\n",
      "Epoch:    2 | Iter:  271 | Fidelity: 0.012298 | Loss: -0.058401\n",
      "\n",
      "Epoch:    2 | Iter:  281 | Fidelity: 0.013122 | Loss: -0.058647\n",
      "\n",
      "Epoch:    2 | Iter:  291 | Fidelity: 0.014019 | Loss: -0.058933\n",
      "\n",
      "Training finished after 2 epochs.\n",
      "\n",
      "Run took: 33.44630770001095 time.\n",
      "Generator parameters saved to ./generated_data/2025-11-12__16-15-55/saved_model/model-gen(hs).pkl\n",
      "Discriminator parameters saved to ./generated_data/2025-11-12__16-15-55/saved_model/model-dis(hs).pkl\n"
     ]
    }
   ],
   "source": [
    "training_instance = Training(config=config)\n",
    "res = training_instance.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67950bca",
   "metadata": {},
   "source": [
    "- Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c96a575a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator parameters saved to ./models/training_instance.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 2.0821,  0.3276,  0.3547, -1.2632, -2.1999,  1.7712, -0.9676,  0.9081,\n",
       "         0.0482, -1.4554, -0.9164,  0.7000,  1.5715, -0.3665,  1.2260, -1.1903,\n",
       "        -0.1509, -0.2416,  0.4665, -0.1350, -0.2492, -0.6871,  2.0001, -1.4148],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./models/training_instance.pkl\"\n",
    "training_instance.gen.save_model_params(path)\n",
    "training_instance.gen.ansatz.theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87820cf0",
   "metadata": {},
   "source": [
    "- Load parameters in new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "126a4354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator parameters loaded successfully from ./models/training_instance.pkl\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([ 2.0821,  0.3276,  0.3547, -1.2632, -2.1999,  1.7712, -0.9676,  0.9081,\n",
       "         0.0482, -1.4554, -0.9164,  0.7000,  1.5715, -0.3665,  1.2260, -1.1903,\n",
       "        -0.1509, -0.2416,  0.4665, -0.1350, -0.2492, -0.6871,  2.0001, -1.4148],\n",
       "       requires_grad=True)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"./models/training_instance.pkl\"\n",
    "training_instance2 = Training(config=config)\n",
    "training_instance2.gen.load_model_params(path)\n",
    "training_instance2.gen.ansatz.theta\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "938d5133",
   "metadata": {},
   "source": [
    "- Retrain training instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "865c3c8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================== \n",
      "run_timestamp: 2025-11-12__16-15-55,\n",
      "----------------------------------------------\n",
      "load_timestamp: None,\n",
      "type_of_warm_start: none,\n",
      "warm_start_strength: 0.1,\n",
      "----------------------------------------------\n",
      "system_size: 3,\n",
      "extra_ancilla: False,\n",
      "ancilla_mode: pass,\n",
      "ancilla_project_norm: re-norm,\n",
      "ancilla_topology: bridge,\n",
      "ancilla_connect_to: None,\n",
      "do_ancilla_1q_gates: True,\n",
      "start_ancilla_gates_randomly: True,\n",
      "----------------------------------------------\n",
      "gen_layers: 3,\n",
      "gen_ansatz: ZZ_X_Z,\n",
      "----------------------------------------------\n",
      "target_hamiltonian: custom_h,\n",
      "custom_hamiltonian_terms: ['ZZZ'],\n",
      "custom_hamiltonian_strengths: [1.0],\n",
      "----------------------------------------------\n",
      "epochs: 2,\n",
      "iterations_epoch: 300,\n",
      "log_every_x_iter: 10,\n",
      "save_fid_and_loss_every_x_iter: 1,\n",
      "max_fidelity: 0.99,\n",
      "steps_gen: 1,\n",
      "steps_dis: 1,\n",
      "----------------------------------------------\n",
      "l_rate: 0.01,\n",
      "momentum_coeff: 0.9,\n",
      "================================================== \n",
      "\n",
      "\n",
      "Epoch:    1 | Iter:    1 | Fidelity: 0.015035 | Loss: -3.522198\n",
      "\n",
      "Epoch:    1 | Iter:   11 | Fidelity: 0.020992 | Loss: -3.421573\n",
      "\n",
      "Epoch:    1 | Iter:   21 | Fidelity: 0.027568 | Loss: -3.243952\n",
      "\n",
      "Epoch:    1 | Iter:   31 | Fidelity: 0.029627 | Loss: -2.950095\n",
      "\n",
      "Epoch:    1 | Iter:   41 | Fidelity: 0.029382 | Loss: -2.724653\n",
      "\n",
      "Epoch:    1 | Iter:   51 | Fidelity: 0.034591 | Loss: -2.229110\n",
      "\n",
      "Epoch:    1 | Iter:   61 | Fidelity: 0.039705 | Loss: -1.406562\n",
      "\n",
      "Epoch:    1 | Iter:   71 | Fidelity: 0.042511 | Loss: -1.278231\n",
      "\n",
      "Epoch:    1 | Iter:   81 | Fidelity: 0.045700 | Loss: -1.079367\n",
      "\n",
      "Epoch:    1 | Iter:   91 | Fidelity: 0.050143 | Loss: -0.674048\n",
      "\n",
      "Epoch:    1 | Iter:  101 | Fidelity: 0.055809 | Loss: 0.116703\n",
      "\n",
      "Epoch:    1 | Iter:  111 | Fidelity: 0.063037 | Loss: 0.429742\n",
      "\n",
      "Epoch:    1 | Iter:  121 | Fidelity: 0.071735 | Loss: 0.412443\n",
      "\n",
      "Epoch:    1 | Iter:  131 | Fidelity: 0.081891 | Loss: 0.433878\n",
      "\n",
      "Epoch:    1 | Iter:  141 | Fidelity: 0.093757 | Loss: 0.438899\n",
      "\n",
      "Epoch:    1 | Iter:  151 | Fidelity: 0.107682 | Loss: 0.433676\n",
      "\n",
      "Epoch:    1 | Iter:  161 | Fidelity: 0.124056 | Loss: 0.426028\n",
      "\n",
      "Epoch:    1 | Iter:  171 | Fidelity: 0.143332 | Loss: 0.417121\n",
      "\n",
      "Epoch:    1 | Iter:  181 | Fidelity: 0.166054 | Loss: 0.405909\n",
      "\n",
      "Epoch:    1 | Iter:  191 | Fidelity: 0.192834 | Loss: 0.392694\n",
      "\n",
      "Epoch:    1 | Iter:  201 | Fidelity: 0.224250 | Loss: 0.377146\n",
      "\n",
      "Epoch:    1 | Iter:  211 | Fidelity: 0.260701 | Loss: 0.359126\n",
      "\n",
      "Epoch:    1 | Iter:  221 | Fidelity: 0.302186 | Loss: 0.338624\n",
      "\n",
      "Epoch:    1 | Iter:  231 | Fidelity: 0.348018 | Loss: 0.316017\n",
      "\n",
      "Epoch:    1 | Iter:  241 | Fidelity: 0.396611 | Loss: 0.292088\n",
      "\n",
      "Epoch:    1 | Iter:  251 | Fidelity: 0.445556 | Loss: 0.268036\n",
      "\n",
      "Epoch:    1 | Iter:  261 | Fidelity: 0.492120 | Loss: 0.245191\n",
      "\n",
      "Epoch:    1 | Iter:  271 | Fidelity: 0.534006 | Loss: 0.224675\n",
      "\n",
      "Epoch:    1 | Iter:  281 | Fidelity: 0.569921 | Loss: 0.207101\n",
      "\n",
      "Epoch:    1 | Iter:  291 | Fidelity: 0.599633 | Loss: 0.192577\n",
      "\n",
      "Epoch:    2 | Iter:    1 | Fidelity: 0.623621 | Loss: 0.180862\n",
      "\n",
      "Epoch:    2 | Iter:   11 | Fidelity: 0.642667 | Loss: 0.171564\n",
      "\n",
      "Epoch:    2 | Iter:   21 | Fidelity: 0.657599 | Loss: 0.164271\n",
      "\n",
      "Epoch:    2 | Iter:   31 | Fidelity: 0.669187 | Loss: 0.158619\n",
      "\n",
      "Epoch:    2 | Iter:   41 | Fidelity: 0.678109 | Loss: 0.154265\n",
      "\n",
      "Epoch:    2 | Iter:   51 | Fidelity: 0.684941 | Loss: 0.150930\n",
      "\n",
      "Epoch:    2 | Iter:   61 | Fidelity: 0.690159 | Loss: 0.148392\n",
      "\n",
      "Epoch:    2 | Iter:   71 | Fidelity: 0.694142 | Loss: 0.146452\n",
      "\n",
      "Epoch:    2 | Iter:   81 | Fidelity: 0.697189 | Loss: 0.144966\n",
      "\n",
      "Epoch:    2 | Iter:   91 | Fidelity: 0.699524 | Loss: 0.143826\n",
      "\n",
      "Epoch:    2 | Iter:  101 | Fidelity: 0.701321 | Loss: 0.142958\n",
      "\n",
      "Epoch:    2 | Iter:  111 | Fidelity: 0.702710 | Loss: 0.142282\n",
      "\n",
      "Epoch:    2 | Iter:  121 | Fidelity: 0.703788 | Loss: 0.141757\n",
      "\n",
      "Epoch:    2 | Iter:  131 | Fidelity: 0.704629 | Loss: 0.141349\n",
      "\n",
      "Epoch:    2 | Iter:  141 | Fidelity: 0.705287 | Loss: 0.141029\n",
      "\n",
      "Epoch:    2 | Iter:  151 | Fidelity: 0.705805 | Loss: 0.140780\n",
      "\n",
      "Epoch:    2 | Iter:  161 | Fidelity: 0.706214 | Loss: 0.140583\n",
      "\n",
      "Epoch:    2 | Iter:  171 | Fidelity: 0.706537 | Loss: 0.140432\n",
      "\n",
      "Epoch:    2 | Iter:  181 | Fidelity: 0.706796 | Loss: 0.140306\n",
      "\n",
      "Epoch:    2 | Iter:  191 | Fidelity: 0.707002 | Loss: 0.140209\n",
      "\n",
      "Epoch:    2 | Iter:  201 | Fidelity: 0.707167 | Loss: 0.140134\n",
      "\n",
      "Epoch:    2 | Iter:  211 | Fidelity: 0.707300 | Loss: 0.140071\n",
      "\n",
      "Epoch:    2 | Iter:  221 | Fidelity: 0.707408 | Loss: 0.140019\n",
      "\n",
      "Epoch:    2 | Iter:  231 | Fidelity: 0.707496 | Loss: 0.139979\n",
      "\n",
      "Epoch:    2 | Iter:  241 | Fidelity: 0.707567 | Loss: 0.139949\n",
      "\n",
      "Epoch:    2 | Iter:  251 | Fidelity: 0.707625 | Loss: 0.139926\n",
      "\n",
      "Epoch:    2 | Iter:  261 | Fidelity: 0.707674 | Loss: 0.139906\n",
      "\n",
      "Epoch:    2 | Iter:  271 | Fidelity: 0.707714 | Loss: 0.139887\n",
      "\n",
      "Epoch:    2 | Iter:  281 | Fidelity: 0.707747 | Loss: 0.139871\n",
      "\n",
      "Epoch:    2 | Iter:  291 | Fidelity: 0.707775 | Loss: 0.139859\n",
      "\n",
      "Training finished after 2 epochs.\n",
      "\n",
      "Run took: 32.33706280007027 time.\n",
      "Generator parameters saved to ./generated_data/2025-11-12__16-15-55/saved_model/model-gen(hs).pkl\n",
      "Discriminator parameters saved to ./generated_data/2025-11-12__16-15-55/saved_model/model-dis(hs).pkl\n"
     ]
    }
   ],
   "source": [
    "res2 = training_instance2.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6a7876c",
   "metadata": {},
   "source": [
    "## 2. Discriminator "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e78207",
   "metadata": {},
   "source": [
    "### 2.1. Same configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ca3edc",
   "metadata": {},
   "source": [
    "We load both generator and discriminator parameters since the generator is before in the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "496804ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = copy.deepcopy(CFG)\n",
    "config.epochs = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d87a62c5",
   "metadata": {},
   "source": [
    "- Run training instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1ad1ece1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================== \n",
      "run_timestamp: 2025-11-12__16-15-55,\n",
      "----------------------------------------------\n",
      "load_timestamp: None,\n",
      "type_of_warm_start: none,\n",
      "warm_start_strength: 0.1,\n",
      "----------------------------------------------\n",
      "system_size: 3,\n",
      "extra_ancilla: False,\n",
      "ancilla_mode: pass,\n",
      "ancilla_project_norm: re-norm,\n",
      "ancilla_topology: bridge,\n",
      "ancilla_connect_to: None,\n",
      "do_ancilla_1q_gates: True,\n",
      "start_ancilla_gates_randomly: True,\n",
      "----------------------------------------------\n",
      "gen_layers: 3,\n",
      "gen_ansatz: ZZ_X_Z,\n",
      "----------------------------------------------\n",
      "target_hamiltonian: custom_h,\n",
      "custom_hamiltonian_terms: ['ZZZ'],\n",
      "custom_hamiltonian_strengths: [1.0],\n",
      "----------------------------------------------\n",
      "epochs: 2,\n",
      "iterations_epoch: 300,\n",
      "log_every_x_iter: 10,\n",
      "save_fid_and_loss_every_x_iter: 1,\n",
      "max_fidelity: 0.99,\n",
      "steps_gen: 1,\n",
      "steps_dis: 1,\n",
      "----------------------------------------------\n",
      "l_rate: 0.01,\n",
      "momentum_coeff: 0.9,\n",
      "================================================== \n",
      "\n",
      "\n",
      "Epoch:    1 | Iter:    1 | Fidelity: 0.010500 | Loss: -3.855820\n",
      "\n",
      "Epoch:    1 | Iter:   11 | Fidelity: 0.012422 | Loss: -3.194337\n",
      "\n",
      "Epoch:    1 | Iter:   21 | Fidelity: 0.014834 | Loss: -2.837650\n",
      "\n",
      "Epoch:    1 | Iter:   31 | Fidelity: 0.016933 | Loss: -2.603093\n",
      "\n",
      "Epoch:    1 | Iter:   41 | Fidelity: 0.020093 | Loss: -2.389363\n",
      "\n",
      "Epoch:    1 | Iter:   51 | Fidelity: 0.028885 | Loss: -1.977955\n",
      "\n",
      "Epoch:    1 | Iter:   61 | Fidelity: 0.046339 | Loss: -0.421372\n",
      "\n",
      "Epoch:    1 | Iter:   71 | Fidelity: 0.061896 | Loss: -0.226690\n",
      "\n",
      "Epoch:    1 | Iter:   81 | Fidelity: 0.074780 | Loss: -0.140532\n",
      "\n",
      "Epoch:    1 | Iter:   91 | Fidelity: 0.087018 | Loss: -0.110956\n",
      "\n",
      "Epoch:    1 | Iter:  101 | Fidelity: 0.099827 | Loss: -0.101651\n",
      "\n",
      "Epoch:    1 | Iter:  111 | Fidelity: 0.113562 | Loss: -0.108414\n",
      "\n",
      "Epoch:    1 | Iter:  121 | Fidelity: 0.128306 | Loss: -0.112655\n",
      "\n",
      "Epoch:    1 | Iter:  131 | Fidelity: 0.144019 | Loss: -0.120058\n",
      "\n",
      "Epoch:    1 | Iter:  141 | Fidelity: 0.160577 | Loss: -0.127660\n",
      "\n",
      "Epoch:    1 | Iter:  151 | Fidelity: 0.177748 | Loss: -0.135769\n",
      "\n",
      "Epoch:    1 | Iter:  161 | Fidelity: 0.195282 | Loss: -0.144055\n",
      "\n",
      "Epoch:    1 | Iter:  171 | Fidelity: 0.212938 | Loss: -0.152425\n",
      "\n",
      "Epoch:    1 | Iter:  181 | Fidelity: 0.230483 | Loss: -0.160774\n",
      "\n",
      "Epoch:    1 | Iter:  191 | Fidelity: 0.247720 | Loss: -0.169022\n",
      "\n",
      "Epoch:    1 | Iter:  201 | Fidelity: 0.264507 | Loss: -0.177109\n",
      "\n",
      "Epoch:    1 | Iter:  211 | Fidelity: 0.280750 | Loss: -0.185012\n",
      "\n",
      "Epoch:    1 | Iter:  221 | Fidelity: 0.296402 | Loss: -0.192706\n",
      "\n",
      "Epoch:    1 | Iter:  231 | Fidelity: 0.311453 | Loss: -0.200182\n",
      "\n",
      "Epoch:    1 | Iter:  241 | Fidelity: 0.325920 | Loss: -0.207458\n",
      "\n",
      "Epoch:    1 | Iter:  251 | Fidelity: 0.339827 | Loss: -0.214529\n",
      "\n",
      "Epoch:    1 | Iter:  261 | Fidelity: 0.353192 | Loss: -0.221383\n",
      "\n",
      "Epoch:    1 | Iter:  271 | Fidelity: 0.366006 | Loss: -0.227991\n",
      "\n",
      "Epoch:    1 | Iter:  281 | Fidelity: 0.378218 | Loss: -0.234312\n",
      "\n",
      "Epoch:    1 | Iter:  291 | Fidelity: 0.389742 | Loss: -0.240276\n",
      "\n",
      "Epoch:    2 | Iter:    1 | Fidelity: 0.400465 | Loss: -0.245817\n",
      "\n",
      "Epoch:    2 | Iter:   11 | Fidelity: 0.410272 | Loss: -0.250856\n",
      "\n",
      "Epoch:    2 | Iter:   21 | Fidelity: 0.419082 | Loss: -0.255364\n",
      "\n",
      "Epoch:    2 | Iter:   31 | Fidelity: 0.426857 | Loss: -0.259315\n",
      "\n",
      "Epoch:    2 | Iter:   41 | Fidelity: 0.433618 | Loss: -0.262724\n",
      "\n",
      "Epoch:    2 | Iter:   51 | Fidelity: 0.439431 | Loss: -0.265635\n",
      "\n",
      "Epoch:    2 | Iter:   61 | Fidelity: 0.444394 | Loss: -0.268102\n",
      "\n",
      "Epoch:    2 | Iter:   71 | Fidelity: 0.448618 | Loss: -0.270191\n",
      "\n",
      "Epoch:    2 | Iter:   81 | Fidelity: 0.452213 | Loss: -0.271956\n",
      "\n",
      "Epoch:    2 | Iter:   91 | Fidelity: 0.455275 | Loss: -0.273447\n",
      "\n",
      "Epoch:    2 | Iter:  101 | Fidelity: 0.457892 | Loss: -0.274719\n",
      "\n",
      "Epoch:    2 | Iter:  111 | Fidelity: 0.460133 | Loss: -0.275797\n",
      "\n",
      "Epoch:    2 | Iter:  121 | Fidelity: 0.462058 | Loss: -0.276725\n",
      "\n",
      "Epoch:    2 | Iter:  131 | Fidelity: 0.463717 | Loss: -0.277518\n",
      "\n",
      "Epoch:    2 | Iter:  141 | Fidelity: 0.465149 | Loss: -0.278195\n",
      "\n",
      "Epoch:    2 | Iter:  151 | Fidelity: 0.466389 | Loss: -0.278778\n",
      "\n",
      "Epoch:    2 | Iter:  161 | Fidelity: 0.467465 | Loss: -0.279278\n",
      "\n",
      "Epoch:    2 | Iter:  171 | Fidelity: 0.468404 | Loss: -0.279723\n",
      "\n",
      "Epoch:    2 | Iter:  181 | Fidelity: 0.469224 | Loss: -0.280103\n",
      "\n",
      "Epoch:    2 | Iter:  191 | Fidelity: 0.469942 | Loss: -0.280430\n",
      "\n",
      "Epoch:    2 | Iter:  201 | Fidelity: 0.470574 | Loss: -0.280715\n",
      "\n",
      "Epoch:    2 | Iter:  211 | Fidelity: 0.471134 | Loss: -0.280972\n",
      "\n",
      "Epoch:    2 | Iter:  221 | Fidelity: 0.471629 | Loss: -0.281196\n",
      "\n",
      "Epoch:    2 | Iter:  231 | Fidelity: 0.472071 | Loss: -0.281390\n",
      "\n",
      "Epoch:    2 | Iter:  241 | Fidelity: 0.472466 | Loss: -0.281562\n",
      "\n",
      "Epoch:    2 | Iter:  251 | Fidelity: 0.472820 | Loss: -0.281719\n",
      "\n",
      "Epoch:    2 | Iter:  261 | Fidelity: 0.473140 | Loss: -0.281856\n",
      "\n",
      "Epoch:    2 | Iter:  271 | Fidelity: 0.473429 | Loss: -0.281983\n",
      "\n",
      "Epoch:    2 | Iter:  281 | Fidelity: 0.473691 | Loss: -0.282092\n",
      "\n",
      "Epoch:    2 | Iter:  291 | Fidelity: 0.473931 | Loss: -0.282193\n",
      "\n",
      "Training finished after 2 epochs.\n",
      "\n",
      "Run took: 31.771730599924922 time.\n",
      "Generator parameters saved to ./generated_data/2025-11-12__16-15-55/saved_model/model-gen(hs).pkl\n",
      "Discriminator parameters saved to ./generated_data/2025-11-12__16-15-55/saved_model/model-dis(hs).pkl\n"
     ]
    }
   ],
   "source": [
    "training_instance = Training(config=config)\n",
    "res = training_instance.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65f87fcb",
   "metadata": {},
   "source": [
    "- Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d1132a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator parameters saved to ./models/training_instance_dis.pkl\n",
      "Generator parameters saved to ./models/training_instance_gen.pkl\n",
      "alpha \n",
      " Parameter containing:\n",
      "tensor([[-3.6876e-07,  1.2350e+00, -4.0861e-01, -5.6506e-05],\n",
      "        [ 4.2349e-05, -3.7194e-01, -1.2213e+00, -2.6650e-05],\n",
      "        [-4.0357e-05,  1.8282e+00, -2.3950e-01,  5.5090e-04],\n",
      "        [-6.5524e-06,  3.6389e-01, -1.0989e+00,  8.6501e-04],\n",
      "        [-2.4459e-06,  1.4325e+00,  4.3625e-01,  9.4373e-05],\n",
      "        [-3.3197e-05,  2.4061e-01, -1.8349e+00,  1.8738e-03]],\n",
      "       requires_grad=True)\n",
      "beta \n",
      " Parameter containing:\n",
      "tensor([[ 0.9332, -0.5044,  0.0472,  0.5852],\n",
      "        [ 0.1334, -0.2799,  0.2476, -0.1272],\n",
      "        [-0.1052,  0.1828, -0.0079, -0.1241],\n",
      "        [-0.1445,  0.1600,  0.5170,  0.0058],\n",
      "        [-0.1212, -0.2877,  0.1003, -0.8243],\n",
      "        [-0.2579, -0.8039,  0.1805,  0.2673]], requires_grad=True)\n",
      "theta \n",
      " Parameter containing:\n",
      "tensor([ 1.2700, -0.7655, -0.0031, -0.8665,  0.0899,  0.2360,  1.3704, -1.2303,\n",
      "         0.1045,  0.7757,  0.0304, -0.7449, -0.2070,  0.7622, -1.3290, -0.2139,\n",
      "        -1.2739,  1.5643, -0.0200,  0.0402,  0.1854,  0.5732, -1.6864, -0.1349],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "path_dis = \"./models/training_instance_dis.pkl\"\n",
    "path_gen = \"./models/training_instance_gen.pkl\"\n",
    "training_instance.dis.save_model_params(path_dis)\n",
    "training_instance.gen.save_model_params(path_gen)\n",
    "print('alpha \\n', training_instance.dis.alpha)\n",
    "print('beta \\n', training_instance.dis.beta)\n",
    "print('theta \\n', training_instance.gen.ansatz.theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd968299",
   "metadata": {},
   "source": [
    "- Load parameters in new model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3c0c869e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Discriminator parameters loaded successfully from ./models/training_instance_dis.pkl\n",
      "Generator parameters loaded successfully from ./models/training_instance_gen.pkl\n",
      "alpha \n",
      " Parameter containing:\n",
      "tensor([[-3.6876e-07,  1.2350e+00, -4.0861e-01, -5.6506e-05],\n",
      "        [ 4.2349e-05, -3.7194e-01, -1.2213e+00, -2.6650e-05],\n",
      "        [-4.0357e-05,  1.8282e+00, -2.3950e-01,  5.5090e-04],\n",
      "        [-6.5524e-06,  3.6389e-01, -1.0989e+00,  8.6501e-04],\n",
      "        [-2.4459e-06,  1.4325e+00,  4.3625e-01,  9.4373e-05],\n",
      "        [-3.3197e-05,  2.4061e-01, -1.8349e+00,  1.8738e-03]],\n",
      "       requires_grad=True)\n",
      "beta \n",
      " Parameter containing:\n",
      "tensor([[ 0.9332, -0.5044,  0.0472,  0.5852],\n",
      "        [ 0.1334, -0.2799,  0.2476, -0.1272],\n",
      "        [-0.1052,  0.1828, -0.0079, -0.1241],\n",
      "        [-0.1445,  0.1600,  0.5170,  0.0058],\n",
      "        [-0.1212, -0.2877,  0.1003, -0.8243],\n",
      "        [-0.2579, -0.8039,  0.1805,  0.2673]], requires_grad=True)\n",
      "theta \n",
      " Parameter containing:\n",
      "tensor([ 1.2700, -0.7655, -0.0031, -0.8665,  0.0899,  0.2360,  1.3704, -1.2303,\n",
      "         0.1045,  0.7757,  0.0304, -0.7449, -0.2070,  0.7622, -1.3290, -0.2139,\n",
      "        -1.2739,  1.5643, -0.0200,  0.0402,  0.1854,  0.5732, -1.6864, -0.1349],\n",
      "       requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "path = \"./models/training_instance_dis.pkl\"\n",
    "training_instance2 = Training(config=config)\n",
    "training_instance2.dis.load_model_params(path_dis)\n",
    "training_instance2.gen.load_model_params(path_gen)\n",
    "print('alpha \\n', training_instance2.dis.alpha)\n",
    "print('beta \\n', training_instance2.dis.beta)\n",
    "print('theta \\n', training_instance2.gen.ansatz.theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cd7b60",
   "metadata": {},
   "source": [
    "- Retrain training instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b4e1f5f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================== \n",
      "run_timestamp: 2025-11-12__16-15-55,\n",
      "----------------------------------------------\n",
      "load_timestamp: None,\n",
      "type_of_warm_start: none,\n",
      "warm_start_strength: 0.1,\n",
      "----------------------------------------------\n",
      "system_size: 3,\n",
      "extra_ancilla: False,\n",
      "ancilla_mode: pass,\n",
      "ancilla_project_norm: re-norm,\n",
      "ancilla_topology: bridge,\n",
      "ancilla_connect_to: None,\n",
      "do_ancilla_1q_gates: True,\n",
      "start_ancilla_gates_randomly: True,\n",
      "----------------------------------------------\n",
      "gen_layers: 3,\n",
      "gen_ansatz: ZZ_X_Z,\n",
      "----------------------------------------------\n",
      "target_hamiltonian: custom_h,\n",
      "custom_hamiltonian_terms: ['ZZZ'],\n",
      "custom_hamiltonian_strengths: [1.0],\n",
      "----------------------------------------------\n",
      "epochs: 2,\n",
      "iterations_epoch: 300,\n",
      "log_every_x_iter: 10,\n",
      "save_fid_and_loss_every_x_iter: 1,\n",
      "max_fidelity: 0.99,\n",
      "steps_gen: 1,\n",
      "steps_dis: 1,\n",
      "----------------------------------------------\n",
      "l_rate: 0.01,\n",
      "momentum_coeff: 0.9,\n",
      "================================================== \n",
      "\n",
      "\n",
      "Epoch:    1 | Iter:    1 | Fidelity: 0.474130 | Loss: -0.282278\n",
      "\n",
      "Epoch:    1 | Iter:   11 | Fidelity: 0.474225 | Loss: -0.282315\n",
      "\n",
      "Epoch:    1 | Iter:   21 | Fidelity: 0.474381 | Loss: -0.282386\n",
      "\n",
      "Epoch:    1 | Iter:   31 | Fidelity: 0.474550 | Loss: -0.282454\n",
      "\n",
      "Epoch:    1 | Iter:   41 | Fidelity: 0.474714 | Loss: -0.282518\n",
      "\n",
      "Epoch:    1 | Iter:   51 | Fidelity: 0.474870 | Loss: -0.282582\n",
      "\n",
      "Epoch:    1 | Iter:   61 | Fidelity: 0.475015 | Loss: -0.282641\n",
      "\n",
      "Epoch:    1 | Iter:   71 | Fidelity: 0.475149 | Loss: -0.282691\n",
      "\n",
      "Epoch:    1 | Iter:   81 | Fidelity: 0.475275 | Loss: -0.282742\n",
      "\n",
      "Epoch:    1 | Iter:   91 | Fidelity: 0.475392 | Loss: -0.282789\n",
      "\n",
      "Epoch:    1 | Iter:  101 | Fidelity: 0.475502 | Loss: -0.282832\n",
      "\n",
      "Epoch:    1 | Iter:  111 | Fidelity: 0.475604 | Loss: -0.282868\n",
      "\n",
      "Epoch:    1 | Iter:  121 | Fidelity: 0.475700 | Loss: -0.282907\n",
      "\n",
      "Epoch:    1 | Iter:  131 | Fidelity: 0.475789 | Loss: -0.282938\n",
      "\n",
      "Epoch:    1 | Iter:  141 | Fidelity: 0.475873 | Loss: -0.282971\n",
      "\n",
      "Epoch:    1 | Iter:  151 | Fidelity: 0.475952 | Loss: -0.282996\n",
      "\n",
      "Epoch:    1 | Iter:  161 | Fidelity: 0.476027 | Loss: -0.283029\n",
      "\n",
      "Epoch:    1 | Iter:  171 | Fidelity: 0.476097 | Loss: -0.283052\n",
      "\n",
      "Epoch:    1 | Iter:  181 | Fidelity: 0.476162 | Loss: -0.283072\n",
      "\n",
      "Epoch:    1 | Iter:  191 | Fidelity: 0.476225 | Loss: -0.283096\n",
      "\n",
      "Epoch:    1 | Iter:  201 | Fidelity: 0.476283 | Loss: -0.283115\n",
      "\n",
      "Epoch:    1 | Iter:  211 | Fidelity: 0.476338 | Loss: -0.283135\n",
      "\n",
      "Epoch:    1 | Iter:  221 | Fidelity: 0.476390 | Loss: -0.283154\n",
      "\n",
      "Epoch:    1 | Iter:  231 | Fidelity: 0.476439 | Loss: -0.283165\n",
      "\n",
      "Epoch:    1 | Iter:  241 | Fidelity: 0.476486 | Loss: -0.283182\n",
      "\n",
      "Epoch:    1 | Iter:  251 | Fidelity: 0.476529 | Loss: -0.283193\n",
      "\n",
      "Epoch:    1 | Iter:  261 | Fidelity: 0.476571 | Loss: -0.283209\n",
      "\n",
      "Epoch:    1 | Iter:  271 | Fidelity: 0.476610 | Loss: -0.283218\n",
      "\n",
      "Epoch:    1 | Iter:  281 | Fidelity: 0.476647 | Loss: -0.283232\n",
      "\n",
      "Epoch:    1 | Iter:  291 | Fidelity: 0.476682 | Loss: -0.283239\n",
      "\n",
      "Epoch:    2 | Iter:    1 | Fidelity: 0.476715 | Loss: -0.283248\n",
      "\n",
      "Epoch:    2 | Iter:   11 | Fidelity: 0.476747 | Loss: -0.283256\n",
      "\n",
      "Epoch:    2 | Iter:   21 | Fidelity: 0.476777 | Loss: -0.283265\n",
      "\n",
      "Epoch:    2 | Iter:   31 | Fidelity: 0.476805 | Loss: -0.283276\n",
      "\n",
      "Epoch:    2 | Iter:   41 | Fidelity: 0.476831 | Loss: -0.283277\n",
      "\n",
      "Epoch:    2 | Iter:   51 | Fidelity: 0.476857 | Loss: -0.283280\n",
      "\n",
      "Epoch:    2 | Iter:   61 | Fidelity: 0.476880 | Loss: -0.283286\n",
      "\n",
      "Epoch:    2 | Iter:   71 | Fidelity: 0.476903 | Loss: -0.283292\n",
      "\n",
      "Epoch:    2 | Iter:   81 | Fidelity: 0.476925 | Loss: -0.283296\n",
      "\n",
      "Epoch:    2 | Iter:   91 | Fidelity: 0.476945 | Loss: -0.283298\n",
      "\n",
      "Epoch:    2 | Iter:  101 | Fidelity: 0.476964 | Loss: -0.283302\n",
      "\n",
      "Epoch:    2 | Iter:  111 | Fidelity: 0.476982 | Loss: -0.283306\n",
      "\n",
      "Epoch:    2 | Iter:  121 | Fidelity: 0.477000 | Loss: -0.283304\n",
      "\n",
      "Epoch:    2 | Iter:  131 | Fidelity: 0.477016 | Loss: -0.283306\n",
      "\n",
      "Epoch:    2 | Iter:  141 | Fidelity: 0.477032 | Loss: -0.283311\n",
      "\n",
      "Epoch:    2 | Iter:  151 | Fidelity: 0.477046 | Loss: -0.283308\n",
      "\n",
      "Epoch:    2 | Iter:  161 | Fidelity: 0.477060 | Loss: -0.283307\n",
      "\n",
      "Epoch:    2 | Iter:  171 | Fidelity: 0.477073 | Loss: -0.283311\n",
      "\n",
      "Epoch:    2 | Iter:  181 | Fidelity: 0.477086 | Loss: -0.283310\n",
      "\n",
      "Epoch:    2 | Iter:  191 | Fidelity: 0.477098 | Loss: -0.283308\n",
      "\n",
      "Epoch:    2 | Iter:  201 | Fidelity: 0.477109 | Loss: -0.283305\n",
      "\n",
      "Epoch:    2 | Iter:  211 | Fidelity: 0.477120 | Loss: -0.283302\n",
      "\n",
      "Epoch:    2 | Iter:  221 | Fidelity: 0.477130 | Loss: -0.283301\n",
      "\n",
      "Epoch:    2 | Iter:  231 | Fidelity: 0.477139 | Loss: -0.283298\n",
      "\n",
      "Epoch:    2 | Iter:  241 | Fidelity: 0.477149 | Loss: -0.283303\n",
      "\n",
      "Epoch:    2 | Iter:  251 | Fidelity: 0.477157 | Loss: -0.283298\n",
      "\n",
      "Epoch:    2 | Iter:  261 | Fidelity: 0.477165 | Loss: -0.283291\n",
      "\n",
      "Epoch:    2 | Iter:  271 | Fidelity: 0.477173 | Loss: -0.283288\n",
      "\n",
      "Epoch:    2 | Iter:  281 | Fidelity: 0.477181 | Loss: -0.283286\n",
      "\n",
      "Epoch:    2 | Iter:  291 | Fidelity: 0.477187 | Loss: -0.283281\n",
      "\n",
      "Training finished after 2 epochs.\n",
      "\n",
      "Run took: 31.644555100006983 time.\n",
      "Generator parameters saved to ./generated_data/2025-11-12__16-15-55/saved_model/model-gen(hs).pkl\n",
      "Discriminator parameters saved to ./generated_data/2025-11-12__16-15-55/saved_model/model-dis(hs).pkl\n"
     ]
    }
   ],
   "source": [
    "res2 = training_instance2.run()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qgan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
