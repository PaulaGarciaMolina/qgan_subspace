{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d261955",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in SINGLE RUN mode.\n",
      "\n",
      "\n",
      "================================================== \n",
      "run_timestamp: 2025-07-28__14-04-56,\n",
      "----------------------------------------------\n",
      "load_timestamp: None,\n",
      "type_of_warm_start: none,\n",
      "warm_start_strength: 0.1,\n",
      "----------------------------------------------\n",
      "system_size: 2,\n",
      "extra_ancilla: False,\n",
      "ancilla_mode: pass,\n",
      "ancilla_project_norm: re-norm,\n",
      "ancilla_topology: bridge,\n",
      "ancilla_connect_to: None,\n",
      "do_ancilla_1q_gates: False,\n",
      "start_ancilla_gates_randomly: False,\n",
      "----------------------------------------------\n",
      "gen_layers: 1,\n",
      "gen_ansatz: XX_YY_ZZ_Z,\n",
      "----------------------------------------------\n",
      "target_hamiltonian: custom_h,\n",
      "custom_hamiltonian_terms: ['ZZZ', 'ZZ', 'XX', 'XZ'],\n",
      "custom_hamiltonian_strengths: [1.0, 0.1, 0.1, 0.1],\n",
      "----------------------------------------------\n",
      "epochs: 1,\n",
      "iterations_epoch: 300,\n",
      "log_every_x_iter: 10,\n",
      "save_fid_and_loss_every_x_iter: 1,\n",
      "max_fidelity: 0.99,\n",
      "steps_gen: 1,\n",
      "steps_dis: 1,\n",
      "----------------------------------------------\n",
      "l_rate: 0.01,\n",
      "momentum_coeff: 0.9,\n",
      "================================================== \n",
      "\n",
      "\n",
      "Epoch:    1 | Iter:    1 | Fidelity: 0.775442 | Loss: -3.710982\n",
      "\n",
      "Epoch:    1 | Iter:   11 | Fidelity: 0.770844 | Loss: -3.119913\n",
      "\n",
      "Epoch:    1 | Iter:   21 | Fidelity: 0.735422 | Loss: -1.540733\n",
      "\n",
      "Epoch:    1 | Iter:   31 | Fidelity: 0.696576 | Loss: -0.590218\n",
      "\n",
      "Epoch:    1 | Iter:   41 | Fidelity: 0.665452 | Loss: -0.280422\n",
      "\n",
      "Epoch:    1 | Iter:   51 | Fidelity: 0.667817 | Loss: -0.081865\n",
      "\n",
      "Epoch:    1 | Iter:   61 | Fidelity: 0.707020 | Loss: -0.041386\n",
      "\n",
      "Epoch:    1 | Iter:   71 | Fidelity: 0.782808 | Loss: -0.058023\n",
      "\n",
      "Epoch:    1 | Iter:   81 | Fidelity: 0.877018 | Loss: -0.112609\n",
      "\n",
      "Epoch:    1 | Iter:   91 | Fidelity: 0.942665 | Loss: -0.157165\n",
      "\n",
      "Epoch:    1 | Iter:  101 | Fidelity: 0.934338 | Loss: -0.144047\n",
      "\n",
      "Epoch:    1 | Iter:  111 | Fidelity: 0.875586 | Loss: -0.133824\n",
      "\n",
      "Epoch:    1 | Iter:  121 | Fidelity: 0.806670 | Loss: -0.161166\n",
      "\n",
      "Epoch:    1 | Iter:  131 | Fidelity: 0.735940 | Loss: -0.159971\n",
      "\n",
      "Epoch:    1 | Iter:  141 | Fidelity: 0.677692 | Loss: -0.094562\n",
      "\n",
      "Epoch:    1 | Iter:  151 | Fidelity: 0.660648 | Loss: -0.041361\n",
      "\n",
      "Epoch:    1 | Iter:  161 | Fidelity: 0.685470 | Loss: -0.027707\n",
      "\n",
      "Epoch:    1 | Iter:  171 | Fidelity: 0.734215 | Loss: -0.034430\n",
      "\n",
      "Epoch:    1 | Iter:  181 | Fidelity: 0.789874 | Loss: -0.046779\n",
      "\n",
      "Epoch:    1 | Iter:  191 | Fidelity: 0.841627 | Loss: -0.057843\n",
      "\n",
      "Epoch:    1 | Iter:  201 | Fidelity: 0.884209 | Loss: -0.065055\n",
      "\n",
      "Epoch:    1 | Iter:  211 | Fidelity: 0.916370 | Loss: -0.068003\n",
      "\n",
      "Epoch:    1 | Iter:  221 | Fidelity: 0.939182 | Loss: -0.067261\n",
      "\n",
      "Epoch:    1 | Iter:  231 | Fidelity: 0.954706 | Loss: -0.063832\n",
      "\n",
      "Epoch:    1 | Iter:  241 | Fidelity: 0.965092 | Loss: -0.058911\n",
      "\n",
      "Epoch:    1 | Iter:  251 | Fidelity: 0.972049 | Loss: -0.053591\n",
      "\n",
      "Epoch:    1 | Iter:  261 | Fidelity: 0.976569 | Loss: -0.048457\n",
      "\n",
      "Epoch:    1 | Iter:  271 | Fidelity: 0.978972 | Loss: -0.043372\n",
      "\n",
      "Epoch:    1 | Iter:  281 | Fidelity: 0.979287 | Loss: -0.037749\n",
      "\n",
      "Epoch:    1 | Iter:  291 | Fidelity: 0.977828 | Loss: -0.031235\n",
      "\n",
      "Training finished after 1 epochs.\n",
      "\n",
      "Run took: 0:00:06.420344 time.\n",
      "Generator model saved to ./generated_data/2025-07-28__14-04-56/saved_model/model-gen(hs).pkl\n",
      "Discriminator model saved to ./generated_data/2025-07-28__14-04-56/saved_model/model-dis(hs).pkl\n",
      "\n",
      "Default configuration run COMPLETED SUCCESSFULLY.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from config import CFG\n",
    "import copy\n",
    "from tools.training_init import run_single_training\n",
    "\n",
    "config = copy.deepcopy(CFG)\n",
    "\n",
    "config.run_multiple_experiments = False\n",
    "config.system_size = 2\n",
    "config.extra_ancilla = False\n",
    "config.epochs = 1\n",
    "config.iterations_epoch = 300\n",
    "config.gen_layers = 1\n",
    "config.gen_ansatz = \"XX_YY_ZZ_Z\"\n",
    "config.target_hamiltonian = \"custom_h\"\n",
    "config.custom_hamiltonian_terms = [\"ZZZ\", \"ZZ\", \"XX\", \"XZ\"]\n",
    "config.custom_hamiltonian_strengths = [1.0, 0.1, 0.1, 0.1]\n",
    "config.label_suffix = \"c1_2q_1l_noanc_XXYYZZZ_CustomH_ZZZ\"\n",
    "run_single_training(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a47dbfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running in SINGLE RUN mode.\n",
      "\n",
      "\n",
      "================================================== \n",
      "run_timestamp: 2025-07-28__14-04-56,\n",
      "----------------------------------------------\n",
      "load_timestamp: None,\n",
      "type_of_warm_start: none,\n",
      "warm_start_strength: 0.1,\n",
      "----------------------------------------------\n",
      "system_size: 3,\n",
      "extra_ancilla: False,\n",
      "ancilla_mode: pass,\n",
      "ancilla_project_norm: re-norm,\n",
      "ancilla_topology: bridge,\n",
      "ancilla_connect_to: None,\n",
      "do_ancilla_1q_gates: False,\n",
      "start_ancilla_gates_randomly: False,\n",
      "----------------------------------------------\n",
      "gen_layers: 3,\n",
      "gen_ansatz: ZZ_X_Z,\n",
      "----------------------------------------------\n",
      "target_hamiltonian: custom_h,\n",
      "custom_hamiltonian_terms: ['XZ', 'X'],\n",
      "custom_hamiltonian_strengths: [1.0, 0.1],\n",
      "----------------------------------------------\n",
      "epochs: 10,\n",
      "iterations_epoch: 300,\n",
      "log_every_x_iter: 10,\n",
      "save_fid_and_loss_every_x_iter: 1,\n",
      "max_fidelity: 0.99,\n",
      "steps_gen: 1,\n",
      "steps_dis: 1,\n",
      "----------------------------------------------\n",
      "l_rate: 0.01,\n",
      "momentum_coeff: 0.9,\n",
      "================================================== \n",
      "\n",
      "\n",
      "Epoch:    1 | Iter:    1 | Fidelity: 0.001114 | Loss: -4.331360\n",
      "\n",
      "Epoch:    1 | Iter:   11 | Fidelity: 0.005405 | Loss: -3.497377\n",
      "\n",
      "Epoch:    1 | Iter:   21 | Fidelity: 0.015019 | Loss: -3.391383\n",
      "\n",
      "Epoch:    1 | Iter:   31 | Fidelity: 0.022234 | Loss: -3.306206\n",
      "\n",
      "Epoch:    1 | Iter:   41 | Fidelity: 0.025937 | Loss: -3.146509\n",
      "\n",
      "Epoch:    1 | Iter:   51 | Fidelity: 0.026838 | Loss: -3.059905\n",
      "\n",
      "Epoch:    1 | Iter:   61 | Fidelity: 0.025125 | Loss: -2.980969\n",
      "\n",
      "Epoch:    1 | Iter:   71 | Fidelity: 0.021150 | Loss: -2.936164\n",
      "\n",
      "Epoch:    1 | Iter:   81 | Fidelity: 0.016402 | Loss: -2.882651\n",
      "\n",
      "Epoch:    1 | Iter:   91 | Fidelity: 0.011155 | Loss: -2.752328\n",
      "\n",
      "Epoch:    1 | Iter:  101 | Fidelity: 0.004554 | Loss: -2.581988\n",
      "\n",
      "Epoch:    1 | Iter:  111 | Fidelity: 0.001319 | Loss: -2.428556\n",
      "\n",
      "Epoch:    1 | Iter:  121 | Fidelity: 0.001240 | Loss: -2.297737\n",
      "\n",
      "Epoch:    1 | Iter:  131 | Fidelity: 0.001997 | Loss: -1.999882\n",
      "\n",
      "Epoch:    1 | Iter:  141 | Fidelity: 0.002949 | Loss: -0.317056\n",
      "\n",
      "Epoch:    1 | Iter:  151 | Fidelity: 0.003454 | Loss: -0.006030\n",
      "\n",
      "Epoch:    1 | Iter:  161 | Fidelity: 0.003726 | Loss: 0.072608\n",
      "\n",
      "Epoch:    1 | Iter:  171 | Fidelity: 0.003933 | Loss: 0.167930\n",
      "\n",
      "Epoch:    1 | Iter:  181 | Fidelity: 0.004128 | Loss: 0.173380\n",
      "\n",
      "Epoch:    1 | Iter:  191 | Fidelity: 0.004324 | Loss: 0.178329\n",
      "\n",
      "Epoch:    1 | Iter:  201 | Fidelity: 0.004534 | Loss: 0.180192\n",
      "\n",
      "Epoch:    1 | Iter:  211 | Fidelity: 0.004762 | Loss: 0.181266\n",
      "\n",
      "Epoch:    1 | Iter:  221 | Fidelity: 0.005007 | Loss: 0.181730\n",
      "\n",
      "Epoch:    1 | Iter:  231 | Fidelity: 0.005271 | Loss: 0.181882\n",
      "\n",
      "Epoch:    1 | Iter:  241 | Fidelity: 0.005555 | Loss: 0.182027\n",
      "\n",
      "Epoch:    1 | Iter:  251 | Fidelity: 0.005861 | Loss: 0.182094\n",
      "\n",
      "Epoch:    1 | Iter:  261 | Fidelity: 0.006191 | Loss: 0.182113\n",
      "\n",
      "Epoch:    1 | Iter:  271 | Fidelity: 0.006547 | Loss: 0.182094\n",
      "\n",
      "Epoch:    1 | Iter:  281 | Fidelity: 0.006932 | Loss: 0.182048\n",
      "\n",
      "Epoch:    1 | Iter:  291 | Fidelity: 0.007347 | Loss: 0.181966\n",
      "\n",
      "Epoch:    2 | Iter:    1 | Fidelity: 0.007795 | Loss: 0.181862\n",
      "\n",
      "Epoch:    2 | Iter:   11 | Fidelity: 0.008280 | Loss: 0.181720\n",
      "\n",
      "Epoch:    2 | Iter:   21 | Fidelity: 0.008805 | Loss: 0.181550\n",
      "\n",
      "Epoch:    2 | Iter:   31 | Fidelity: 0.009372 | Loss: 0.181355\n",
      "\n",
      "Epoch:    2 | Iter:   41 | Fidelity: 0.009987 | Loss: 0.181131\n",
      "\n",
      "Epoch:    2 | Iter:   51 | Fidelity: 0.010654 | Loss: 0.180869\n",
      "\n",
      "Epoch:    2 | Iter:   61 | Fidelity: 0.011377 | Loss: 0.180581\n",
      "\n",
      "Epoch:    2 | Iter:   71 | Fidelity: 0.012161 | Loss: 0.180256\n",
      "\n",
      "Epoch:    2 | Iter:   81 | Fidelity: 0.013011 | Loss: 0.179894\n",
      "\n",
      "Epoch:    2 | Iter:   91 | Fidelity: 0.013935 | Loss: 0.179487\n",
      "\n",
      "Epoch:    2 | Iter:  101 | Fidelity: 0.014939 | Loss: 0.179044\n",
      "\n",
      "Epoch:    2 | Iter:  111 | Fidelity: 0.016029 | Loss: 0.178552\n",
      "\n",
      "Epoch:    2 | Iter:  121 | Fidelity: 0.017214 | Loss: 0.178012\n",
      "\n",
      "Epoch:    2 | Iter:  131 | Fidelity: 0.018502 | Loss: 0.177418\n",
      "\n",
      "Epoch:    2 | Iter:  141 | Fidelity: 0.019902 | Loss: 0.176766\n",
      "\n",
      "Epoch:    2 | Iter:  151 | Fidelity: 0.021424 | Loss: 0.176052\n",
      "\n",
      "Epoch:    2 | Iter:  161 | Fidelity: 0.023079 | Loss: 0.175266\n",
      "\n",
      "Epoch:    2 | Iter:  171 | Fidelity: 0.024877 | Loss: 0.174413\n",
      "\n",
      "Epoch:    2 | Iter:  181 | Fidelity: 0.026831 | Loss: 0.173477\n",
      "\n",
      "Epoch:    2 | Iter:  191 | Fidelity: 0.028953 | Loss: 0.172457\n",
      "\n",
      "Epoch:    2 | Iter:  201 | Fidelity: 0.031257 | Loss: 0.171349\n",
      "\n",
      "Epoch:    2 | Iter:  211 | Fidelity: 0.033757 | Loss: 0.170142\n",
      "\n",
      "Epoch:    2 | Iter:  221 | Fidelity: 0.036468 | Loss: 0.168829\n",
      "\n",
      "Epoch:    2 | Iter:  231 | Fidelity: 0.039407 | Loss: 0.167398\n",
      "\n",
      "Epoch:    2 | Iter:  241 | Fidelity: 0.042591 | Loss: 0.165849\n",
      "\n",
      "Epoch:    2 | Iter:  251 | Fidelity: 0.046038 | Loss: 0.164177\n",
      "\n",
      "Epoch:    2 | Iter:  261 | Fidelity: 0.049770 | Loss: 0.162352\n",
      "\n",
      "Epoch:    2 | Iter:  271 | Fidelity: 0.053810 | Loss: 0.160382\n",
      "\n",
      "Epoch:    2 | Iter:  281 | Fidelity: 0.058185 | Loss: 0.158243\n",
      "\n",
      "Epoch:    2 | Iter:  291 | Fidelity: 0.062926 | Loss: 0.155937\n",
      "\n",
      "Epoch:    3 | Iter:    1 | Fidelity: 0.068074 | Loss: 0.153421\n",
      "\n",
      "Epoch:    3 | Iter:   11 | Fidelity: 0.073677 | Loss: 0.150689\n",
      "\n",
      "Epoch:    3 | Iter:   21 | Fidelity: 0.079795 | Loss: 0.147700\n",
      "\n",
      "Epoch:    3 | Iter:   31 | Fidelity: 0.086506 | Loss: 0.144430\n",
      "\n",
      "Epoch:    3 | Iter:   41 | Fidelity: 0.093910 | Loss: 0.140813\n",
      "\n",
      "Epoch:    3 | Iter:   51 | Fidelity: 0.102132 | Loss: 0.136804\n",
      "\n",
      "Epoch:    3 | Iter:   61 | Fidelity: 0.111333 | Loss: 0.132321\n",
      "\n",
      "Epoch:    3 | Iter:   71 | Fidelity: 0.121710 | Loss: 0.127264\n",
      "\n",
      "Epoch:    3 | Iter:   81 | Fidelity: 0.133502 | Loss: 0.121517\n",
      "\n",
      "Epoch:    3 | Iter:   91 | Fidelity: 0.146988 | Loss: 0.114964\n",
      "\n",
      "Epoch:    3 | Iter:  101 | Fidelity: 0.162472 | Loss: 0.107446\n",
      "\n",
      "Epoch:    3 | Iter:  111 | Fidelity: 0.180254 | Loss: 0.098815\n",
      "\n",
      "Epoch:    3 | Iter:  121 | Fidelity: 0.200572 | Loss: 0.088969\n",
      "\n",
      "Epoch:    3 | Iter:  131 | Fidelity: 0.223522 | Loss: 0.077865\n",
      "\n",
      "Epoch:    3 | Iter:  141 | Fidelity: 0.248943 | Loss: 0.065574\n",
      "\n",
      "Epoch:    3 | Iter:  151 | Fidelity: 0.276316 | Loss: 0.052361\n",
      "\n",
      "Epoch:    3 | Iter:  161 | Fidelity: 0.304722 | Loss: 0.038661\n",
      "\n",
      "Epoch:    3 | Iter:  171 | Fidelity: 0.332913 | Loss: 0.025070\n",
      "\n",
      "Epoch:    3 | Iter:  181 | Fidelity: 0.359538 | Loss: 0.012239\n",
      "\n",
      "Epoch:    3 | Iter:  191 | Fidelity: 0.383430 | Loss: 0.000728\n",
      "\n",
      "Epoch:    3 | Iter:  201 | Fidelity: 0.403863 | Loss: -0.009130\n",
      "\n",
      "Epoch:    3 | Iter:  211 | Fidelity: 0.420630 | Loss: -0.017231\n",
      "\n",
      "Epoch:    3 | Iter:  221 | Fidelity: 0.433957 | Loss: -0.023686\n",
      "\n",
      "Epoch:    3 | Iter:  231 | Fidelity: 0.444323 | Loss: -0.028723\n",
      "\n",
      "Epoch:    3 | Iter:  241 | Fidelity: 0.452287 | Loss: -0.032606\n",
      "\n",
      "Epoch:    3 | Iter:  251 | Fidelity: 0.458383 | Loss: -0.035592\n",
      "\n",
      "Epoch:    3 | Iter:  261 | Fidelity: 0.463057 | Loss: -0.037900\n",
      "\n",
      "Epoch:    3 | Iter:  271 | Fidelity: 0.466666 | Loss: -0.039688\n",
      "\n",
      "Epoch:    3 | Iter:  281 | Fidelity: 0.469480 | Loss: -0.041088\n",
      "\n",
      "Epoch:    3 | Iter:  291 | Fidelity: 0.471702 | Loss: -0.042203\n",
      "\n",
      "Epoch:    4 | Iter:    1 | Fidelity: 0.473483 | Loss: -0.043100\n",
      "\n",
      "Epoch:    4 | Iter:   11 | Fidelity: 0.474932 | Loss: -0.043830\n",
      "\n",
      "Epoch:    4 | Iter:   21 | Fidelity: 0.476129 | Loss: -0.044438\n",
      "\n",
      "Epoch:    4 | Iter:   31 | Fidelity: 0.477134 | Loss: -0.044948\n",
      "\n",
      "Epoch:    4 | Iter:   41 | Fidelity: 0.477989 | Loss: -0.045379\n",
      "\n",
      "Epoch:    4 | Iter:   51 | Fidelity: 0.478727 | Loss: -0.045758\n",
      "\n",
      "Epoch:    4 | Iter:   61 | Fidelity: 0.479372 | Loss: -0.046081\n",
      "\n",
      "Epoch:    4 | Iter:   71 | Fidelity: 0.479942 | Loss: -0.046367\n",
      "\n",
      "Epoch:    4 | Iter:   81 | Fidelity: 0.480451 | Loss: -0.046620\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mrun_single_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m=\u001b[49m\u001b[43mCFG\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\tools\\training_init.py:46\u001b[39m, in \u001b[36mrun_single_training\u001b[39m\u001b[34m(config)\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     42\u001b[39m     \u001b[38;5;66;03m##############################################################\u001b[39;00m\n\u001b[32m     43\u001b[39m     \u001b[38;5;66;03m# Run single training instance with specified configuration\u001b[39;00m\n\u001b[32m     44\u001b[39m     \u001b[38;5;66;03m##############################################################\u001b[39;00m\n\u001b[32m     45\u001b[39m     training_instance = Training(config=config)\n\u001b[32m---> \u001b[39m\u001b[32m46\u001b[39m     \u001b[43mtraining_instance\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     47\u001b[39m     success_msg = \u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mDefault configuration run COMPLETED SUCCESSFULLY.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     48\u001b[39m     print_and_log(success_msg, config.log_path)  \u001b[38;5;66;03m# Log to file\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\qgan\\training.py:98\u001b[39m, in \u001b[36mTraining.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;66;03m# --- Logging and Monitoring ---\u001b[39;00m\n\u001b[32m     96\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m i % \u001b[38;5;28mself\u001b[39m.config.save_fid_and_loss_every_x_iter == \u001b[32m0\u001b[39m:\n\u001b[32m     97\u001b[39m     \u001b[38;5;66;03m# Use the detached state for fidelity/loss calculation to save memory\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m98\u001b[39m     fid, loss = \u001b[43mcompute_fidelity_and_cost\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfinal_target_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_gen_state_detached\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     99\u001b[39m     epoch_fidelities.append(fid)\n\u001b[32m    100\u001b[39m     epoch_losses.append(loss.item()) \u001b[38;5;66;03m# .item() gets the float value\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\qgan\\cost_functions.py:91\u001b[39m, in \u001b[36mcompute_fidelity_and_cost\u001b[39m\u001b[34m(dis, final_target_state, final_gen_state)\u001b[39m\n\u001b[32m     80\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Calculate the fidelity and cost function\u001b[39;00m\n\u001b[32m     81\u001b[39m \n\u001b[32m     82\u001b[39m \u001b[33;03mArgs:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     88\u001b[39m \u001b[33;03m    tuple[float, float]: the fidelity and cost function.\u001b[39;00m\n\u001b[32m     89\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     90\u001b[39m fidelity = compute_fidelity(final_target_state, final_gen_state)\n\u001b[32m---> \u001b[39m\u001b[32m91\u001b[39m cost = \u001b[43mcompute_cost\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_target_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_gen_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m fidelity, cost\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\qgan\\cost_functions.py:32\u001b[39m, in \u001b[36mcompute_cost\u001b[39m\u001b[34m(dis, final_target_state, final_gen_state, config)\u001b[39m\n\u001b[32m     21\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcompute_cost\u001b[39m(dis, final_target_state: torch.Tensor, final_gen_state: torch.Tensor, config=CFG) -> \u001b[38;5;28mfloat\u001b[39m:\n\u001b[32m     22\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Calculate the cost function. Which is basically equivalent to the Wasserstein distance.\u001b[39;00m\n\u001b[32m     23\u001b[39m \n\u001b[32m     24\u001b[39m \u001b[33;03m    Args:\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m \u001b[33;03m        float: the cost function.\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m     A, B, psi, phi = \u001b[43mdis\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_dis_matrices_rep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m     \u001b[38;5;66;03m# fmt: off\u001b[39;00m\n\u001b[32m     36\u001b[39m     final_gen_state = final_gen_state.flatten()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\f52ga\\CVC\\Codes\\qgan_subspace\\src\\qgan\\discriminator.py:79\u001b[39m, in \u001b[36mDiscriminator.get_dis_matrices_rep\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     77\u001b[39m A = torch.matrix_exp((-\u001b[32m1.0\u001b[39m / lamb) * phi)\n\u001b[32m     78\u001b[39m \u001b[38;5;66;03m# B = expm(1/lamb * psi)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m B = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmatrix_exp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m1.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m/\u001b[49m\u001b[43m \u001b[49m\u001b[43mlamb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m \u001b[49m\u001b[43mpsi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m A, B, psi, phi\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "run_single_training(config=CFG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b618be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qgan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
